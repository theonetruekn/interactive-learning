{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f75dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {},
   "source": [
    "# Evaluating the LLM-Agen on SWE-Benchmark\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-lite.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41741fe9-a4d4-4f56-8f5c-cd0148ee7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                                                        sqlfluff/sqlfluff\n",
       "instance_id                                           sqlfluff__sqlfluff-2862\n",
       "base_commit                          447ecf862a4d2b977d0add9f444655357b9c4f1f\n",
       "patch                       diff --git a/src/sqlfluff/core/linter/common.p...\n",
       "test_patch                  diff --git a/test/api/simple_test.py b/test/ap...\n",
       "problem_statement           fix keep adding new line on wrong place \\n### ...\n",
       "hints_text                  > Version\\r\\n> sqlfluff, version 0.6.2\\r\\n\\r\\n...\n",
       "created_at                                          2022-03-14 19:46:08+00:00\n",
       "version                                                                   0.1\n",
       "FAIL_TO_PASS                [test/api/simple_test.py::test__api__lint_stri...\n",
       "PASS_TO_PASS                [test/api/simple_test.py::test__api__lint_stri...\n",
       "environment_setup_commit             3d52e8270d82aeccf4c516d059a80a6947919aea\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a82b1-185c-4b45-aad8-ed0efb059b5d",
   "metadata": {},
   "source": [
    "# Testing SmolCoder\n",
    "\n",
    "This requires starting the `phi3:latest` model, with ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a127113-b474-4e59-93f9-bb9c8f1ba82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lupos/Agentless', '/home/lupos/miniconda3/envs/llm/lib/python311.zip', '/home/lupos/miniconda3/envs/llm/lib/python3.11', '/home/lupos/miniconda3/envs/llm/lib/python3.11/lib-dynload', '', '/home/lupos/miniconda3/envs/llm/lib/python3.11/site-packages', '/home/lupos/interactive-learning/SmolCoder']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(str(os.path.abspath('SmolCoder')))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14072627-c353-4ee3-aaab-41fb32758e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "from SmolCoder.src.agent_wrapper import AgentWrapper\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.replace_method import ReplaceMethod\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.tools.execute_python import ExecutePythonCode\n",
    "from SmolCoder.src.tools.show_method import ShowMethodBody\n",
    "from SmolCoder.src.tools.move_folder import MoveFolder\n",
    "from SmolCoder.src.tools.human_interaction import HumanInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237bac3c-59a8-4d40-ab75-0cc06c999082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definition\n",
    "class_sumary = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "replace_method = ReplaceMethod()\n",
    "finish = Finish()\n",
    "execute_python = ExecutePythonCode()\n",
    "show_method = ShowMethodBody()\n",
    "move_folder = MoveFolder()\n",
    "human_interaction = HumanInteraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8b706-bc7f-486b-8f55-63d47f19e693",
   "metadata": {},
   "source": [
    "## Testing Execute Python Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5b0734-bc24-40ff-9c95-6fd82f88d021",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m Toolkit([execute_python])\n\u001b[0;32m----> 3\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "tools = Toolkit([execute_python])\n",
    "\n",
    "agent = AgentWrapper(agent_name=\"SmolCoder\",\n",
    "                     toolkit=tools,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "prompt = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0103363a-f353-4b72-9d19-ee9959167721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = agent.predict(prompt)\n",
    "#print(\"RESULT: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94d05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(smolCoder.inspect_history(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78b30-5c0e-49c3-b605-366f1eb6f287",
   "metadata": {},
   "source": [
    "# SmolCoder on SWE\n",
    "\n",
    "This tests SmolCoder on a single Instance of the SWE-Benchmark.\n",
    "This is without first trying to reproduce the bug, just barebones ReAct with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74e473e-0e6b-4b57-a3b1-ed9c97686331",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3f9919-5077-45cd-8768-a8d96b6aa8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mpredict(df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc19c91e-3fc0-471a-a479-c5bff68803fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6494f-e13c-4e01-a860-86a8af311e54",
   "metadata": {},
   "source": [
    "## Generating all Predictions\n",
    "\n",
    "When running this on a server, it could happen that something crashed or an error is thrown which doesn't get catches, as such it is important to write the changes to disk for each entry in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentStub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#tools = Toolkit([class_sumary, list_classes, list_files, finish])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#model = LLM(\"phi3:latest\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m stub \u001b[38;5;241m=\u001b[39m \u001b[43mAgentStub\u001b[49m()\n\u001b[1;32m     13\u001b[0m agent \u001b[38;5;241m=\u001b[39m AgentWrapper(stub, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m checkpoint_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AgentStub' is not defined"
     ]
    }
   ],
   "source": [
    "# This implementation uses checkpoints, this means if the program \n",
    "# is interuppted it can start again, where it left oft.\n",
    "\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "#tools = Toolkit([class_sumary, list_classes, list_files, finish])\n",
    "#model = LLM(\"phi3:latest\")\n",
    "#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\n",
    "#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\n",
    "\n",
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "checkpoint_file = 'checkpoint.txt'\n",
    "resume_index = 0\n",
    "\n",
    "activated = 1\n",
    "\n",
    "if activated:\n",
    "    # Check if checkpoint file exists and read the last processed index\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            resume_index = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint file: {e}\")\n",
    "    \n",
    "    if resume_index < len(df) - 1:\n",
    "        # Open a file to save predictions\n",
    "        with open('predictions.json', 'a', encoding=\"utf-8-sig\") as json_file:\n",
    "            if resume_index == 0:\n",
    "                json_file.write('[')  # Start of JSON array\n",
    "                json_file.write('\\n')\n",
    "            # Generating our solution\n",
    "            for index, row in df.iterrows():\n",
    "                if index % 10 == 0: print(\"Current idx: \" + str(index))\n",
    "                # Skip rows that were already processed\n",
    "                if index < resume_index:\n",
    "                    continue\n",
    "        \n",
    "                predictions = {\n",
    "                    \"instance_id\": row[\"instance_id\"],\n",
    "                    \"model_patch\": agent.predict(row),\n",
    "                    \"model_name_or_path\": agent.name\n",
    "                }\n",
    "                # Convert the dictionary to a JSON formatted string and write to file\n",
    "                json_data = json.dumps(predictions, indent=4)\n",
    "                json_file.write(json_data)\n",
    "                if index < len(df) - 1:\n",
    "                    json_file.write(',')\n",
    "                json_file.write('\\n')\n",
    "        \n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    f.write(str(index))\n",
    "                    \n",
    "            if index == len(df) - 1:\n",
    "                json_file.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ff1e1",
   "metadata": {},
   "source": [
    "# Meta Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cbbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.prompting_strategy import PromptingStrategy\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.meta_tokenizer import MetaTokenizer\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()\n",
    "\n",
    "list_methods = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "finish = Finish()\n",
    "\n",
    "toolkit = Toolkit([list_methods, list_classes, list_files, finish])\n",
    "\n",
    "smol = SmolCoder(phase=0, model=LLM(\"llama3.1\", openai=[False, \"None\"], logger=None), codebase_dir= Path(\"test_codebase/\"), logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31b2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIND SUS FILES PHASE:\n",
      "\n",
      "\n",
      "You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is, to solve this issue. First you will be given a tree structure of the codebase, your task is it based on the description of the issue to select relevant files of it for closer inspection. After this you will be provided with a skeleten for each of your slected file, this skeleton will consist out of class and method headers and your task will be to select the classes and methods that are relevant to the described issue. At the end you will be provided with the source code of your selected classes and methos and asked to fix it.\n",
      "--------------------------------------------\n",
      "You will now be given the description of the GitHub Issue: \n",
      "\n",
      "Enable quiet mode/no-verbose in CLI for use in pre-commit hook\n",
      "There seems to be only an option to increase the level of verbosity when using SQLFluff [CLI](https://docs.sqlfluff.com/en/stable/cli.html), not to limit it further.\n",
      "\n",
      "It would be great to have an option to further limit the amount of prints when running `sqlfluff fix`, especially in combination with deployment using a pre-commit hook. For example, only print the return status and the number of fixes applied, similar to how it is when using `black` in a pre-commit hook:\n",
      "![image](https://user-images.githubusercontent.com/10177212/140480676-dc98d00b-4383-44f2-bb90-3301a6eedec2.png)\n",
      "\n",
      "This hides the potentially long list of fixes that are being applied to the SQL files, which can get quite verbose.\n",
      "\n",
      "--------------------------------------------\n",
      "You will now be given the structure of codebase corresponding to the Issue:\n",
      "```\n",
      "setup.py\n",
      "util.py\n",
      "docs/source/conf.py\n",
      "examples/02_timing_api_steps.py\n",
      "examples/03_getting_rules_and_dialects.py\n",
      "examples/01_basic_api_usage.py\n",
      "plugins/sqlfluff-templater-dbt/setup.py\n",
      "plugins/sqlfluff-templater-dbt/test/rules_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/templater_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/linter_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/__init__.py\n",
      "plugins/sqlfluff-templater-dbt/test/generate_packages_yml.py\n",
      "plugins/sqlfluff-templater-dbt/test/fixtures/dbt/templater.py\n",
      "plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/templater.py\n",
      "plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/__init__.py\n",
      "plugins/sqlfluff-plugin-example/setup.py\n",
      "plugins/sqlfluff-plugin-example/test/rules/rule_test_cases_test.py\n",
      "plugins/sqlfluff-plugin-example/src/example/rules.py\n",
      "plugins/sqlfluff-plugin-example/src/example/__init__.py\n",
      "test/conftest.py\n",
      "test/generate_parse_fixture_yml.py\n",
      "test/__init__.py\n",
      "test/test_testing.py\n",
      "test/diff_quality_plugin_test.py\n",
      "test/fixtures/rules/custom/S000.py\n",
      "test/fixtures/rules/custom/L000.py\n",
      "test/fixtures/rules/custom/bad_rule_name/E000.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/bar/baz.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/bar/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/other/__init__.py\n",
      "test/fixtures/templater/jinja_j_libraries/libs/foo.py\n",
      "test/fixtures/templater/jinja_j_libraries/libs/bar.py\n",
      "test/api/__init__.py\n",
      "test/api/classes_test.py\n",
      "test/api/info_test.py\n",
      "test/api/simple_test.py\n",
      "test/rules/std_L027_test.py\n",
      "test/rules/std_L019_test.py\n",
      "test/rules/std_roundtrip_test.py\n",
      "test/rules/std_L054_test.py\n",
      "test/rules/std_fix_auto_test.py\n",
      "test/rules/std_L016_L36_combo_test.py\n",
      "test/rules/yaml_test_cases_test.py\n",
      "test/rules/std_L003_L036_L039_combo_test.py\n",
      "test/rules/std_L048_test.py\n",
      "test/rules/std_L003_test.py\n",
      "test/rules/std_L008_test.py\n",
      "test/rules/std_L020_test.py\n",
      "test/rules/std_test.py\n",
      "test/rules/std_L007_test.py\n",
      "test/rules/std_L009_L052_test.py\n",
      "test/dialects/exasol_test.py\n",
      "test/dialects/conftest.py\n",
      "test/dialects/postgres_test.py\n",
      "test/dialects/snowflake_test.py\n",
      "test/dialects/bigquery_test.py\n",
      "test/dialects/dialects_test.py\n",
      "test/dialects/ansi_test.py\n",
      "test/dialects/__init__.py\n",
      "test/cli/autocomplete_test.py\n",
      "test/cli/commands_test.py\n",
      "test/cli/formatters_test.py\n",
      "test/cli/__init__.py\n",
      "test/cli/helpers_test.py\n",
      "test/core/string_helpers_test.py\n",
      "test/core/linter_test.py\n",
      "test/core/config_test.py\n",
      "test/core/__init__.py\n",
      "test/core/file_helpers_test.py\n",
      "test/core/plugin_test.py\n",
      "test/core/rules/docstring_test.py\n",
      "test/core/rules/config_test.py\n",
      "test/core/rules/__init__.py\n",
      "test/core/rules/functional/test_raw_file_slices.py\n",
      "test/core/rules/functional/test_segments.py\n",
      "test/core/parser/conftest.py\n",
      "test/core/parser/markers_test.py\n",
      "test/core/parser/segments_base_test.py\n",
      "test/core/parser/segments_common_test.py\n",
      "test/core/parser/lexer_test.py\n",
      "test/core/parser/parse_test.py\n",
      "test/core/parser/__init__.py\n",
      "test/core/parser/helpers_test.py\n",
      "test/core/parser/grammar_test.py\n",
      "test/core/templaters/python_test.py\n",
      "test/core/templaters/base_test.py\n",
      "test/core/templaters/__init__.py\n",
      "test/core/templaters/placeholder_test.py\n",
      "test/core/templaters/jinja_test.py\n",
      "src/sqlfluff/diff_quality_plugin.py\n",
      "src/sqlfluff/__init__.py\n",
      "src/sqlfluff/__main__.py\n",
      "src/sqlfluff/testing/rules.py\n",
      "src/sqlfluff/testing/__init__.py\n",
      "src/sqlfluff/api/info.py\n",
      "src/sqlfluff/api/simple.py\n",
      "src/sqlfluff/api/__init__.py\n",
      "src/sqlfluff/rules/L006.py\n",
      "src/sqlfluff/rules/L051.py\n",
      "src/sqlfluff/rules/L049.py\n",
      "src/sqlfluff/rules/L008.py\n",
      "src/sqlfluff/rules/L045.py\n",
      "src/sqlfluff/rules/L040.py\n",
      "src/sqlfluff/rules/L043.py\n",
      "src/sqlfluff/rules/L005.py\n",
      "src/sqlfluff/rules/L022.py\n",
      "src/sqlfluff/rules/L015.py\n",
      "src/sqlfluff/rules/L034.py\n",
      "src/sqlfluff/rules/L038.py\n",
      "src/sqlfluff/rules/L012.py\n",
      "src/sqlfluff/rules/L059.py\n",
      "src/sqlfluff/rules/L002.py\n",
      "src/sqlfluff/rules/L057.py\n",
      "src/sqlfluff/rules/L054.py\n",
      "src/sqlfluff/rules/L031.py\n",
      "src/sqlfluff/rules/L013.py\n",
      "src/sqlfluff/rules/L025.py\n",
      "src/sqlfluff/rules/L035.py\n",
      "src/sqlfluff/rules/L010.py\n",
      "src/sqlfluff/rules/L032.py\n",
      "src/sqlfluff/rules/L058.py\n",
      "src/sqlfluff/rules/L052.py\n",
      "src/sqlfluff/rules/L018.py\n",
      "src/sqlfluff/rules/L016.py\n",
      "src/sqlfluff/rules/L046.py\n",
      "src/sqlfluff/rules/L056.py\n",
      "src/sqlfluff/rules/L009.py\n",
      "src/sqlfluff/rules/L053.py\n",
      "src/sqlfluff/rules/L029.py\n",
      "src/sqlfluff/rules/L028.py\n",
      "src/sqlfluff/rules/L019.py\n",
      "src/sqlfluff/rules/L033.py\n",
      "src/sqlfluff/rules/L020.py\n",
      "src/sqlfluff/rules/L042.py\n",
      "src/sqlfluff/rules/L024.py\n",
      "src/sqlfluff/rules/L044.py\n",
      "src/sqlfluff/rules/L048.py\n",
      "src/sqlfluff/rules/L001.py\n",
      "src/sqlfluff/rules/L011.py\n",
      "src/sqlfluff/rules/L023.py\n",
      "src/sqlfluff/rules/__init__.py\n",
      "src/sqlfluff/rules/L003.py\n",
      "src/sqlfluff/rules/L014.py\n",
      "src/sqlfluff/rules/L055.py\n",
      "src/sqlfluff/rules/L017.py\n",
      "src/sqlfluff/rules/L026.py\n",
      "src/sqlfluff/rules/L027.py\n",
      "src/sqlfluff/rules/L004.py\n",
      "src/sqlfluff/rules/L047.py\n",
      "src/sqlfluff/rules/L007.py\n",
      "src/sqlfluff/rules/L036.py\n",
      "src/sqlfluff/rules/L041.py\n",
      "src/sqlfluff/rules/L039.py\n",
      "src/sqlfluff/rules/L030.py\n",
      "src/sqlfluff/rules/L037.py\n",
      "src/sqlfluff/rules/L021.py\n",
      "src/sqlfluff/rules/L050.py\n",
      "src/sqlfluff/dialects/dialect_spark3_keywords.py\n",
      "src/sqlfluff/dialects/dialect_exasol_keywords.py\n",
      "src/sqlfluff/dialects/dialect_teradata.py\n",
      "src/sqlfluff/dialects/dialect_tsql_keywords.py\n",
      "src/sqlfluff/dialects/dialect_ansi_keywords.py\n",
      "src/sqlfluff/dialects/dialect_bigquery.py\n",
      "src/sqlfluff/dialects/dialect_hive_keywords.py\n",
      "src/sqlfluff/dialects/dialect_ansi.py\n",
      "src/sqlfluff/dialects/dialect_postgres_keywords.py\n",
      "src/sqlfluff/dialects/dialect_bigquery_keywords.py\n",
      "src/sqlfluff/dialects/dialect_mysql.py\n",
      "src/sqlfluff/dialects/dialect_snowflake.py\n",
      "src/sqlfluff/dialects/dialect_oracle.py\n",
      "src/sqlfluff/dialects/dialect_exasol.py\n",
      "src/sqlfluff/dialects/dialect_tsql.py\n",
      "src/sqlfluff/dialects/dialect_hive.py\n",
      "src/sqlfluff/dialects/dialect_redshift.py\n",
      "src/sqlfluff/dialects/__init__.py\n",
      "src/sqlfluff/dialects/dialect_sqlite.py\n",
      "src/sqlfluff/dialects/dialect_postgres.py\n",
      "src/sqlfluff/dialects/dialect_spark3.py\n",
      "src/sqlfluff/dialects/dialect_redshift_keywords.py\n",
      "src/sqlfluff/dialects/dialect_snowflake_keywords.py\n",
      "src/sqlfluff/cli/autocomplete.py\n",
      "src/sqlfluff/cli/commands.py\n",
      "src/sqlfluff/cli/helpers.py\n",
      "src/sqlfluff/cli/__init__.py\n",
      "src/sqlfluff/cli/formatters.py\n",
      "src/sqlfluff/core/enums.py\n",
      "src/sqlfluff/core/cached_property.py\n",
      "src/sqlfluff/core/timing.py\n",
      "src/sqlfluff/core/file_helpers.py\n",
      "src/sqlfluff/core/__init__.py\n",
      "src/sqlfluff/core/string_helpers.py\n",
      "src/sqlfluff/core/config.py\n",
      "src/sqlfluff/core/errors.py\n",
      "src/sqlfluff/core/plugin/lib.py\n",
      "src/sqlfluff/core/plugin/host.py\n",
      "src/sqlfluff/core/plugin/__init__.py\n",
      "src/sqlfluff/core/plugin/hookspecs.py\n",
      "src/sqlfluff/core/linter/linting_result.py\n",
      "src/sqlfluff/core/linter/runner.py\n",
      "src/sqlfluff/core/linter/linted_dir.py\n",
      "src/sqlfluff/core/linter/linted_file.py\n",
      "src/sqlfluff/core/linter/linter.py\n",
      "src/sqlfluff/core/linter/__init__.py\n",
      "src/sqlfluff/core/linter/common.py\n",
      "src/sqlfluff/core/rules/loader.py\n",
      "src/sqlfluff/core/rules/base.py\n",
      "src/sqlfluff/core/rules/config_info.py\n",
      "src/sqlfluff/core/rules/doc_decorators.py\n",
      "src/sqlfluff/core/rules/__init__.py\n",
      "src/sqlfluff/core/rules/analysis/select_crawler.py\n",
      "src/sqlfluff/core/rules/analysis/select.py\n",
      "src/sqlfluff/core/rules/analysis/__init__.py\n",
      "src/sqlfluff/core/rules/functional/segments.py\n",
      "src/sqlfluff/core/rules/functional/templated_file_slice_predicates.py\n",
      "src/sqlfluff/core/rules/functional/raw_file_slices.py\n",
      "src/sqlfluff/core/rules/functional/segment_predicates.py\n",
      "src/sqlfluff/core/rules/functional/raw_file_slice_predicates.py\n",
      "src/sqlfluff/core/rules/functional/__init__.py\n",
      "src/sqlfluff/core/rules/functional/templated_file_slices.py\n",
      "src/sqlfluff/core/dialects/base.py\n",
      "src/sqlfluff/core/dialects/__init__.py\n",
      "src/sqlfluff/core/dialects/common.py\n",
      "src/sqlfluff/core/parser/markers.py\n",
      "src/sqlfluff/core/parser/parsers.py\n",
      "src/sqlfluff/core/parser/parser.py\n",
      "src/sqlfluff/core/parser/lexer.py\n",
      "src/sqlfluff/core/parser/helpers.py\n",
      "src/sqlfluff/core/parser/__init__.py\n",
      "src/sqlfluff/core/parser/matchable.py\n",
      "src/sqlfluff/core/parser/context.py\n",
      "src/sqlfluff/core/parser/match_logging.py\n",
      "src/sqlfluff/core/parser/match_wrapper.py\n",
      "src/sqlfluff/core/parser/match_result.py\n",
      "src/sqlfluff/core/parser/grammar/anyof.py\n",
      "src/sqlfluff/core/parser/grammar/conditional.py\n",
      "src/sqlfluff/core/parser/grammar/base.py\n",
      "src/sqlfluff/core/parser/grammar/noncode.py\n",
      "src/sqlfluff/core/parser/grammar/delimited.py\n",
      "src/sqlfluff/core/parser/grammar/sequence.py\n",
      "src/sqlfluff/core/parser/grammar/greedy.py\n",
      "src/sqlfluff/core/parser/grammar/__init__.py\n",
      "src/sqlfluff/core/parser/segments/base.py\n",
      "src/sqlfluff/core/parser/segments/meta.py\n",
      "src/sqlfluff/core/parser/segments/raw.py\n",
      "src/sqlfluff/core/parser/segments/generator.py\n",
      "src/sqlfluff/core/parser/segments/__init__.py\n",
      "src/sqlfluff/core/parser/segments/ephemeral.py\n",
      "src/sqlfluff/core/templaters/base.py\n",
      "src/sqlfluff/core/templaters/jinja.py\n",
      "src/sqlfluff/core/templaters/__init__.py\n",
      "src/sqlfluff/core/templaters/placeholder.py\n",
      "src/sqlfluff/core/templaters/python.py\n",
      "src/sqlfluff/core/templaters/slicers/tracer.py\n",
      "src/sqlfluff/core/templaters/slicers/heuristic.py\n",
      "src/sqlfluff/core/templaters/slicers/__init__.py\n",
      "```\n",
      "--------------------------------------------\n",
      "Now that you have seen structure of the codebase please select files that you think are relevenat to the issue. Please provide the list of file paths in plain text format, without any whitespaces. Each file path should be on a new line and without any whitespaces. At the end of the list, include the specific stop token `--- END OF LIST ---` to indicate the end of the list.\n",
      "\n",
      "Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "The returned files should be separated by new lines.\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "For example:\n",
      "/documents/report.py\n",
      "/pictures/vacation.py\n",
      "/music/song.py\n",
      "--- END OF LIST ---\n",
      "\n",
      "To repeat:\n",
      "- Each file path should be listed on its own line.\n",
      "- After the last file path, include the stop token `--- END OF LIST ---` on a new line. This token indicates the end of the file paths list.\n",
      "- There should be no additional formatting or characters besides the file paths and the stop token.\n",
      "- DO NOT USE WHITESPACE\n",
      "Your file list:\n",
      "src/sqlfluff/core/cached_property.py\n",
      "src/sqlfluff/core/timing.py\n",
      "src/sqlfluff/core/linter/linted_file.py\n",
      "src/sqlfluff/core/parser/match_result.py\n",
      "src/sqlfluff/core/templaters/slicers/heuristic.py\n",
      "\n",
      "--- END OF LIST ---\n",
      "You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is, to solve this issue. First you will be given a tree structure of the codebase, your task is it based on the description of the issue to select relevant files of it for closer inspection. After this you will be provided with a skeleten for each of your slected file, this skeleton will consist out of class and method headers and your task will be to select the classes and methods that are relevant to the described issue. At the end you will be provided with the source code of your selected classes and methos and asked to fix it.\n",
      "--------------------------------------------\n",
      "You will now be given the description of the GitHub Issue: \n",
      "\n",
      "Enable quiet mode/no-verbose in CLI for use in pre-commit hook\n",
      "There seems to be only an option to increase the level of verbosity when using SQLFluff [CLI](https://docs.sqlfluff.com/en/stable/cli.html), not to limit it further.\n",
      "\n",
      "It would be great to have an option to further limit the amount of prints when running `sqlfluff fix`, especially in combination with deployment using a pre-commit hook. For example, only print the return status and the number of fixes applied, similar to how it is when using `black` in a pre-commit hook:\n",
      "![image](https://user-images.githubusercontent.com/10177212/140480676-dc98d00b-4383-44f2-bb90-3301a6eedec2.png)\n",
      "\n",
      "This hides the potentially long list of fixes that are being applied to the SQL files, which can get quite verbose.\n",
      "\n",
      "--------------------------------------------\n",
      "You will now be given the structure of codebase corresponding to the Issue:\n",
      "```\n",
      "setup.py\n",
      "util.py\n",
      "docs/source/conf.py\n",
      "examples/02_timing_api_steps.py\n",
      "examples/03_getting_rules_and_dialects.py\n",
      "examples/01_basic_api_usage.py\n",
      "plugins/sqlfluff-templater-dbt/setup.py\n",
      "plugins/sqlfluff-templater-dbt/test/rules_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/templater_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/linter_test.py\n",
      "plugins/sqlfluff-templater-dbt/test/__init__.py\n",
      "plugins/sqlfluff-templater-dbt/test/generate_packages_yml.py\n",
      "plugins/sqlfluff-templater-dbt/test/fixtures/dbt/templater.py\n",
      "plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/templater.py\n",
      "plugins/sqlfluff-templater-dbt/sqlfluff_templater_dbt/__init__.py\n",
      "plugins/sqlfluff-plugin-example/setup.py\n",
      "plugins/sqlfluff-plugin-example/test/rules/rule_test_cases_test.py\n",
      "plugins/sqlfluff-plugin-example/src/example/rules.py\n",
      "plugins/sqlfluff-plugin-example/src/example/__init__.py\n",
      "test/conftest.py\n",
      "test/generate_parse_fixture_yml.py\n",
      "test/__init__.py\n",
      "test/test_testing.py\n",
      "test/diff_quality_plugin_test.py\n",
      "test/fixtures/rules/custom/S000.py\n",
      "test/fixtures/rules/custom/L000.py\n",
      "test/fixtures/rules/custom/bad_rule_name/E000.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/bar/baz.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/libs/foo/bar/__init__.py\n",
      "test/fixtures/templater/jinja_m_libraries_module/other/__init__.py\n",
      "test/fixtures/templater/jinja_j_libraries/libs/foo.py\n",
      "test/fixtures/templater/jinja_j_libraries/libs/bar.py\n",
      "test/api/__init__.py\n",
      "test/api/classes_test.py\n",
      "test/api/info_test.py\n",
      "test/api/simple_test.py\n",
      "test/rules/std_L027_test.py\n",
      "test/rules/std_L019_test.py\n",
      "test/rules/std_roundtrip_test.py\n",
      "test/rules/std_L054_test.py\n",
      "test/rules/std_fix_auto_test.py\n",
      "test/rules/std_L016_L36_combo_test.py\n",
      "test/rules/yaml_test_cases_test.py\n",
      "test/rules/std_L003_L036_L039_combo_test.py\n",
      "test/rules/std_L048_test.py\n",
      "test/rules/std_L003_test.py\n",
      "test/rules/std_L008_test.py\n",
      "test/rules/std_L020_test.py\n",
      "test/rules/std_test.py\n",
      "test/rules/std_L007_test.py\n",
      "test/rules/std_L009_L052_test.py\n",
      "test/dialects/exasol_test.py\n",
      "test/dialects/conftest.py\n",
      "test/dialects/postgres_test.py\n",
      "test/dialects/snowflake_test.py\n",
      "test/dialects/bigquery_test.py\n",
      "test/dialects/dialects_test.py\n",
      "test/dialects/ansi_test.py\n",
      "test/dialects/__init__.py\n",
      "test/cli/autocomplete_test.py\n",
      "test/cli/commands_test.py\n",
      "test/cli/formatters_test.py\n",
      "test/cli/__init__.py\n",
      "test/cli/helpers_test.py\n",
      "test/core/string_helpers_test.py\n",
      "test/core/linter_test.py\n",
      "test/core/config_test.py\n",
      "test/core/__init__.py\n",
      "test/core/file_helpers_test.py\n",
      "test/core/plugin_test.py\n",
      "test/core/rules/docstring_test.py\n",
      "test/core/rules/config_test.py\n",
      "test/core/rules/__init__.py\n",
      "test/core/rules/functional/test_raw_file_slices.py\n",
      "test/core/rules/functional/test_segments.py\n",
      "test/core/parser/conftest.py\n",
      "test/core/parser/markers_test.py\n",
      "test/core/parser/segments_base_test.py\n",
      "test/core/parser/segments_common_test.py\n",
      "test/core/parser/lexer_test.py\n",
      "test/core/parser/parse_test.py\n",
      "test/core/parser/__init__.py\n",
      "test/core/parser/helpers_test.py\n",
      "test/core/parser/grammar_test.py\n",
      "test/core/templaters/python_test.py\n",
      "test/core/templaters/base_test.py\n",
      "test/core/templaters/__init__.py\n",
      "test/core/templaters/placeholder_test.py\n",
      "test/core/templaters/jinja_test.py\n",
      "src/sqlfluff/diff_quality_plugin.py\n",
      "src/sqlfluff/__init__.py\n",
      "src/sqlfluff/__main__.py\n",
      "src/sqlfluff/testing/rules.py\n",
      "src/sqlfluff/testing/__init__.py\n",
      "src/sqlfluff/api/info.py\n",
      "src/sqlfluff/api/simple.py\n",
      "src/sqlfluff/api/__init__.py\n",
      "src/sqlfluff/rules/L006.py\n",
      "src/sqlfluff/rules/L051.py\n",
      "src/sqlfluff/rules/L049.py\n",
      "src/sqlfluff/rules/L008.py\n",
      "src/sqlfluff/rules/L045.py\n",
      "src/sqlfluff/rules/L040.py\n",
      "src/sqlfluff/rules/L043.py\n",
      "src/sqlfluff/rules/L005.py\n",
      "src/sqlfluff/rules/L022.py\n",
      "src/sqlfluff/rules/L015.py\n",
      "src/sqlfluff/rules/L034.py\n",
      "src/sqlfluff/rules/L038.py\n",
      "src/sqlfluff/rules/L012.py\n",
      "src/sqlfluff/rules/L059.py\n",
      "src/sqlfluff/rules/L002.py\n",
      "src/sqlfluff/rules/L057.py\n",
      "src/sqlfluff/rules/L054.py\n",
      "src/sqlfluff/rules/L031.py\n",
      "src/sqlfluff/rules/L013.py\n",
      "src/sqlfluff/rules/L025.py\n",
      "src/sqlfluff/rules/L035.py\n",
      "src/sqlfluff/rules/L010.py\n",
      "src/sqlfluff/rules/L032.py\n",
      "src/sqlfluff/rules/L058.py\n",
      "src/sqlfluff/rules/L052.py\n",
      "src/sqlfluff/rules/L018.py\n",
      "src/sqlfluff/rules/L016.py\n",
      "src/sqlfluff/rules/L046.py\n",
      "src/sqlfluff/rules/L056.py\n",
      "src/sqlfluff/rules/L009.py\n",
      "src/sqlfluff/rules/L053.py\n",
      "src/sqlfluff/rules/L029.py\n",
      "src/sqlfluff/rules/L028.py\n",
      "src/sqlfluff/rules/L019.py\n",
      "src/sqlfluff/rules/L033.py\n",
      "src/sqlfluff/rules/L020.py\n",
      "src/sqlfluff/rules/L042.py\n",
      "src/sqlfluff/rules/L024.py\n",
      "src/sqlfluff/rules/L044.py\n",
      "src/sqlfluff/rules/L048.py\n",
      "src/sqlfluff/rules/L001.py\n",
      "src/sqlfluff/rules/L011.py\n",
      "src/sqlfluff/rules/L023.py\n",
      "src/sqlfluff/rules/__init__.py\n",
      "src/sqlfluff/rules/L003.py\n",
      "src/sqlfluff/rules/L014.py\n",
      "src/sqlfluff/rules/L055.py\n",
      "src/sqlfluff/rules/L017.py\n",
      "src/sqlfluff/rules/L026.py\n",
      "src/sqlfluff/rules/L027.py\n",
      "src/sqlfluff/rules/L004.py\n",
      "src/sqlfluff/rules/L047.py\n",
      "src/sqlfluff/rules/L007.py\n",
      "src/sqlfluff/rules/L036.py\n",
      "src/sqlfluff/rules/L041.py\n",
      "src/sqlfluff/rules/L039.py\n",
      "src/sqlfluff/rules/L030.py\n",
      "src/sqlfluff/rules/L037.py\n",
      "src/sqlfluff/rules/L021.py\n",
      "src/sqlfluff/rules/L050.py\n",
      "src/sqlfluff/dialects/dialect_spark3_keywords.py\n",
      "src/sqlfluff/dialects/dialect_exasol_keywords.py\n",
      "src/sqlfluff/dialects/dialect_teradata.py\n",
      "src/sqlfluff/dialects/dialect_tsql_keywords.py\n",
      "src/sqlfluff/dialects/dialect_ansi_keywords.py\n",
      "src/sqlfluff/dialects/dialect_bigquery.py\n",
      "src/sqlfluff/dialects/dialect_hive_keywords.py\n",
      "src/sqlfluff/dialects/dialect_ansi.py\n",
      "src/sqlfluff/dialects/dialect_postgres_keywords.py\n",
      "src/sqlfluff/dialects/dialect_bigquery_keywords.py\n",
      "src/sqlfluff/dialects/dialect_mysql.py\n",
      "src/sqlfluff/dialects/dialect_snowflake.py\n",
      "src/sqlfluff/dialects/dialect_oracle.py\n",
      "src/sqlfluff/dialects/dialect_exasol.py\n",
      "src/sqlfluff/dialects/dialect_tsql.py\n",
      "src/sqlfluff/dialects/dialect_hive.py\n",
      "src/sqlfluff/dialects/dialect_redshift.py\n",
      "src/sqlfluff/dialects/__init__.py\n",
      "src/sqlfluff/dialects/dialect_sqlite.py\n",
      "src/sqlfluff/dialects/dialect_postgres.py\n",
      "src/sqlfluff/dialects/dialect_spark3.py\n",
      "src/sqlfluff/dialects/dialect_redshift_keywords.py\n",
      "src/sqlfluff/dialects/dialect_snowflake_keywords.py\n",
      "src/sqlfluff/cli/autocomplete.py\n",
      "src/sqlfluff/cli/commands.py\n",
      "src/sqlfluff/cli/helpers.py\n",
      "src/sqlfluff/cli/__init__.py\n",
      "src/sqlfluff/cli/formatters.py\n",
      "src/sqlfluff/core/enums.py\n",
      "src/sqlfluff/core/cached_property.py\n",
      "src/sqlfluff/core/timing.py\n",
      "src/sqlfluff/core/file_helpers.py\n",
      "src/sqlfluff/core/__init__.py\n",
      "src/sqlfluff/core/string_helpers.py\n",
      "src/sqlfluff/core/config.py\n",
      "src/sqlfluff/core/errors.py\n",
      "src/sqlfluff/core/plugin/lib.py\n",
      "src/sqlfluff/core/plugin/host.py\n",
      "src/sqlfluff/core/plugin/__init__.py\n",
      "src/sqlfluff/core/plugin/hookspecs.py\n",
      "src/sqlfluff/core/linter/linting_result.py\n",
      "src/sqlfluff/core/linter/runner.py\n",
      "src/sqlfluff/core/linter/linted_dir.py\n",
      "src/sqlfluff/core/linter/linted_file.py\n",
      "src/sqlfluff/core/linter/linter.py\n",
      "src/sqlfluff/core/linter/__init__.py\n",
      "src/sqlfluff/core/linter/common.py\n",
      "src/sqlfluff/core/rules/loader.py\n",
      "src/sqlfluff/core/rules/base.py\n",
      "src/sqlfluff/core/rules/config_info.py\n",
      "src/sqlfluff/core/rules/doc_decorators.py\n",
      "src/sqlfluff/core/rules/__init__.py\n",
      "src/sqlfluff/core/rules/analysis/select_crawler.py\n",
      "src/sqlfluff/core/rules/analysis/select.py\n",
      "src/sqlfluff/core/rules/analysis/__init__.py\n",
      "src/sqlfluff/core/rules/functional/segments.py\n",
      "src/sqlfluff/core/rules/functional/templated_file_slice_predicates.py\n",
      "src/sqlfluff/core/rules/functional/raw_file_slices.py\n",
      "src/sqlfluff/core/rules/functional/segment_predicates.py\n",
      "src/sqlfluff/core/rules/functional/raw_file_slice_predicates.py\n",
      "src/sqlfluff/core/rules/functional/__init__.py\n",
      "src/sqlfluff/core/rules/functional/templated_file_slices.py\n",
      "src/sqlfluff/core/dialects/base.py\n",
      "src/sqlfluff/core/dialects/__init__.py\n",
      "src/sqlfluff/core/dialects/common.py\n",
      "src/sqlfluff/core/parser/markers.py\n",
      "src/sqlfluff/core/parser/parsers.py\n",
      "src/sqlfluff/core/parser/parser.py\n",
      "src/sqlfluff/core/parser/lexer.py\n",
      "src/sqlfluff/core/parser/helpers.py\n",
      "src/sqlfluff/core/parser/__init__.py\n",
      "src/sqlfluff/core/parser/matchable.py\n",
      "src/sqlfluff/core/parser/context.py\n",
      "src/sqlfluff/core/parser/match_logging.py\n",
      "src/sqlfluff/core/parser/match_wrapper.py\n",
      "src/sqlfluff/core/parser/match_result.py\n",
      "src/sqlfluff/core/parser/grammar/anyof.py\n",
      "src/sqlfluff/core/parser/grammar/conditional.py\n",
      "src/sqlfluff/core/parser/grammar/base.py\n",
      "src/sqlfluff/core/parser/grammar/noncode.py\n",
      "src/sqlfluff/core/parser/grammar/delimited.py\n",
      "src/sqlfluff/core/parser/grammar/sequence.py\n",
      "src/sqlfluff/core/parser/grammar/greedy.py\n",
      "src/sqlfluff/core/parser/grammar/__init__.py\n",
      "src/sqlfluff/core/parser/segments/base.py\n",
      "src/sqlfluff/core/parser/segments/meta.py\n",
      "src/sqlfluff/core/parser/segments/raw.py\n",
      "src/sqlfluff/core/parser/segments/generator.py\n",
      "src/sqlfluff/core/parser/segments/__init__.py\n",
      "src/sqlfluff/core/parser/segments/ephemeral.py\n",
      "src/sqlfluff/core/templaters/base.py\n",
      "src/sqlfluff/core/templaters/jinja.py\n",
      "src/sqlfluff/core/templaters/__init__.py\n",
      "src/sqlfluff/core/templaters/placeholder.py\n",
      "src/sqlfluff/core/templaters/python.py\n",
      "src/sqlfluff/core/templaters/slicers/tracer.py\n",
      "src/sqlfluff/core/templaters/slicers/heuristic.py\n",
      "src/sqlfluff/core/templaters/slicers/__init__.py\n",
      "```\n",
      "--------------------------------------------\n",
      "Now that you have seen structure of the codebase please select files that you think are relevenat to the issue. Please provide the list of file paths in plain text format, without any whitespaces. Each file path should be on a new line and without any whitespaces. At the end of the list, include the specific stop token `--- END OF LIST ---` to indicate the end of the list.\n",
      "\n",
      "Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "The returned files should be separated by new lines.\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "For example:\n",
      "/documents/report.py\n",
      "/pictures/vacation.py\n",
      "/music/song.py\n",
      "--- END OF LIST ---\n",
      "\n",
      "To repeat:\n",
      "- Each file path should be listed on its own line.\n",
      "- After the last file path, include the stop token `--- END OF LIST ---` on a new line. This token indicates the end of the file paths list.\n",
      "- There should be no additional formatting or characters besides the file paths and the stop token.\n",
      "- DO NOT USE WHITESPACE\n",
      "Your file list:\n",
      "src/sqlfluff/core/cached_property.py\n",
      "src/sqlfluff/core/timing.py\n",
      "src/sqlfluff/core/linter/linted_file.py\n",
      "src/sqlfluff/core/parser/match_result.py\n",
      "src/sqlfluff/core/templaters/slicers/heuristic.py\n",
      "\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Found the following paths:  ['./repos/sqlfluff/src/sqlfluff/core/cached_property.py', './repos/sqlfluff/src/sqlfluff/core/timing.py', './repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py', './repos/sqlfluff/src/sqlfluff/core/parser/match_result.py', './repos/sqlfluff/src/sqlfluff/core/templaters/slicers/heuristic.py']\n",
      "SUS CLASSES AND FUNCTION PHASE:\n",
      "\n",
      "\n",
      "You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is, to solve this issue. First you will be given a tree structure of the codebase, your task is it based on the description of the issue to select relevant files of it for closer inspection. After this you will be provided with a skeleten for each of your slected file, this skeleton will consist out of class and method headers and your task will be to select the classes and methods that are relevant to the described issue. At the end you will be provided with the source code of your selected classes and methos and asked to fix it.\n",
      "--------------------------------------------\n",
      "You will now be given the description of the GitHub Issue: \n",
      "\n",
      "Enable quiet mode/no-verbose in CLI for use in pre-commit hook\n",
      "There seems to be only an option to increase the level of verbosity when using SQLFluff [CLI](https://docs.sqlfluff.com/en/stable/cli.html), not to limit it further.\n",
      "\n",
      "It would be great to have an option to further limit the amount of prints when running `sqlfluff fix`, especially in combination with deployment using a pre-commit hook. For example, only print the return status and the number of fixes applied, similar to how it is when using `black` in a pre-commit hook:\n",
      "![image](https://user-images.githubusercontent.com/10177212/140480676-dc98d00b-4383-44f2-bb90-3301a6eedec2.png)\n",
      "\n",
      "This hides the potentially long list of fixes that are being applied to the SQL files, which can get quite verbose.\n",
      "\n",
      "--------------------------------------------\n",
      "In a previous iteration you've already found files that might be relevant to the described Issue. We now want to look closer and identify classes and functions that are relevant to the described Issue. For this purpose you will receive a list of classes and function and you should choose ones that are relevant to the described issue.\n",
      "--------------------------------------------\n",
      "You will now be given the headers of classes and function:\n",
      "Headers for ./repos/sqlfluff/src/sqlfluff/core/cached_property.py\n",
      "```\n",
      "```\n",
      "Headers for ./repos/sqlfluff/src/sqlfluff/core/timing.py\n",
      "```\n",
      "Class: TimingSummary\n",
      "  Methods:\n",
      "    Method: __init__\n",
      "    Method: add\n",
      "    Method: summary\n",
      "```\n",
      "Headers for ./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\n",
      "```\n",
      "Class: LintedFile\n",
      "  Methods:\n",
      "    Method: check_tuples\n",
      "    Method: get_violations\n",
      "    Method: _ignore_masked_violations_single_line\n",
      "    Method: _should_ignore_violation_line_range\n",
      "    Method: _ignore_masked_violations_line_range\n",
      "    Method: ignore_masked_violations\n",
      "    Method: num_violations\n",
      "    Method: is_clean\n",
      "    Method: _log_hints\n",
      "    Method: fix_string\n",
      "    Method: persist_tree\n",
      "    Method: _safe_create_replace_file\n",
      "```\n",
      "Headers for ./repos/sqlfluff/src/sqlfluff/core/parser/match_result.py\n",
      "```\n",
      "Class: MatchResult\n",
      "  Methods:\n",
      "    Method: matched_length\n",
      "    Method: all_segments\n",
      "    Method: __len__\n",
      "    Method: is_complete\n",
      "    Method: has_match\n",
      "    Method: __bool__\n",
      "    Method: raw_matched\n",
      "    Method: __str__\n",
      "    Method: __eq__\n",
      "    Method: seg_to_tuple\n",
      "    Method: from_unmatched\n",
      "    Method: from_matched\n",
      "    Method: from_empty\n",
      "    Method: __add__\n",
      "```\n",
      "Headers for ./repos/sqlfluff/src/sqlfluff/core/templaters/slicers/heuristic.py\n",
      "```\n",
      "Function: slice_template\n",
      "\n",
      "Function: _slice_template\n",
      "```\n",
      "--------------------------------------------\n",
      "Now that you have seen, all the classes and function of the relevant files please select classes and function that you think are relevant to the issue. \n",
      "Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "[\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/cached_property.py\",\n",
      "      \"classes\": [\n",
      "          \"CachedProperty\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/timing.py\",\n",
      "      \"classes\": [\n",
      "          \"TimingSummary\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": [\n",
      "          \"_ignore_masked_violations_line_range\",\n",
      "          \"get_violations\",\n",
      "          \"num_violations\"\n",
      "      ]\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/parser/match_result.py\",\n",
      "      \"classes\": [\n",
      "          \"MatchResult\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "While parsing your provided a list of selected classes and functions an error was found: \n",
      "Error: 'selected_functions' at index 0 should be a list.\n",
      "--------------------------------------------\n",
      "Please try again.Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "[\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/cached_property.py\",\n",
      "      \"classes\": [\n",
      "          \"CachedProperty\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/timing.py\",\n",
      "      \"classes\": [\n",
      "          \"TimingSummary\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/parser/match_result.py\",\n",
      "      \"classes\": [\n",
      "          \"MatchResult\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "While parsing your provided a list of selected classes and functions an error was found: \n",
      "Error: 'selected_functions' at index 0 should be a list.\n",
      "--------------------------------------------\n",
      "Please try again.Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "[\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/cached_property.py\",\n",
      "      \"classes\": [\n",
      "          \"CachedProperty\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/timing.py\",\n",
      "      \"classes\": [\n",
      "          \"TimingSummary\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/parser/match_result.py\",\n",
      "      \"classes\": [\n",
      "          \"MatchResult\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": [\"get_violations\"]\n",
      "  }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "While parsing your provided a list of selected classes and functions an error was found: \n",
      "Error: 'selected_functions' at index 0 should be a list.\n",
      "--------------------------------------------\n",
      "Please try again.Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "[\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/cached_property.py\",\n",
      "      \"classes\": [\n",
      "          \"CachedProperty\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/timing.py\",\n",
      "      \"classes\": [\n",
      "          \"TimingSummary\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/parser/match_result.py\",\n",
      "      \"classes\": [\n",
      "          \"MatchResult\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "While parsing your provided a list of selected classes and functions an error was found: \n",
      "Error: 'selected_functions' at index 0 should be a list.\n",
      "--------------------------------------------\n",
      "Please try again.Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "[\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/cached_property.py\",\n",
      "      \"classes\": [\n",
      "          \"CachedProperty\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/timing.py\",\n",
      "      \"classes\": [\n",
      "          \"TimingSummary\"\n",
      "      ],\n",
      "      \"functions\": []\n",
      "  },\n",
      "  {\n",
      "      \"file_path\": \"./repos/sqlfluff/src/sqlfluff/core/linter/linted_file.py\",\n",
      "      \"classes\": [],\n",
      "      \"functions\": [\"get_violations\"]\n",
      "  }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "--------------------------------------------\n",
      "While parsing your provided a list of selected classes and functions an error was found: \n",
      "Error: 'selected_functions' at index 0 should be a list.\n",
      "--------------------------------------------\n",
      "Please try again.Please provide a list of classes or functions in JSON file format. Use an array, where each entry has the following elements: `file_path`, `selected_functions`, and `selected_classes`. The `file_path` should point to the file containing the `selected_functions` and `selected_classes`, which are arrays. Please only provide the full path and return at most 5 files. Do not provide commentary.\n",
      "End your output with the stop token `--- END OF LIST ---`.\n",
      "\n",
      "DO NOT ADD ANYTHING ELSE TO YOUR RESPONSE.\n",
      "\n",
      "**Example Output:**\n",
      "[\n",
      "    {\n",
      "        \"file_path\": \"/torch/nn/attention/bias.py\",\n",
      "        \"selected_functions\": [\"causal_upper_left\", \"causal_upper_right\"],\n",
      "        \"selected_classes\": [\"CausalVariant\", \"CausalBias\"]\n",
      "    },\n",
      "    {\n",
      "        \"file_path\": \"/torch/fx/passes/reinplace.py\",\n",
      "        \"selected_functions\": [],\n",
      "        \"selected_classes\": [\"_ViewType\"]\n",
      "    }\n",
      "]\n",
      "--- END OF LIST ---\n",
      "\n",
      "Your class and function list:\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Sucks to suck, LLM didn't find only valid classes/functions.\n",
      "SUS CODE SNIPPET PHASE: \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msmol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_statement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_cwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./repos/sqlfluff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/interactive-learning/SmolCoder/src/agent.py:108\u001b[0m, in \u001b[0;36mSmolCoder.__call__\u001b[0;34m(self, userprompt, number_of_tries, start_cwd)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     95\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     96\u001b[0m                 {\n\u001b[1;32m     97\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./repos/sqlfluff/src/sqlfluff/core/parser/lexer.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 },\n\u001b[1;32m    107\u001b[0m             ]\n\u001b[0;32m--> 108\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_sus_code_snippets\u001b[49m\u001b[43m(\u001b[49m\u001b[43msysprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m#  REPAIR CODE\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/interactive-learning/SmolCoder/src/agent.py:609\u001b[0m, in \u001b[0;36mSmolCoder.find_sus_code_snippets\u001b[0;34m(self, sysprompt, data, max_tries)\u001b[0m\n\u001b[1;32m    606\u001b[0m relevant_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# Iterate through each element in the JSON data\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselected_functions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mselected_functions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "smol(df.iloc[0][\"problem_statement\"], start_cwd=\"./repos/sqlfluff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c04035-61e5-4388-a860-8d0b3611e429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20db2d-09a7-46ca-bb99-0ba34b53fa79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
