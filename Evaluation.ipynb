{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {},
   "source": [
    "# Evaluating the LLM-Agen on SWE-Benchmark\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-dev-dataset.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"SWEBench/swe-bench-dev-dataset.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aedaceeb-0820-45ad-baac-8895cf56c96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>base_commit</th>\n",
       "      <th>patch</th>\n",
       "      <th>test_patch</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>hints_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>version</th>\n",
       "      <th>FAIL_TO_PASS</th>\n",
       "      <th>PASS_TO_PASS</th>\n",
       "      <th>environment_setup_commit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sqlfluff/sqlfluff</td>\n",
       "      <td>sqlfluff__sqlfluff-4764</td>\n",
       "      <td>a820c139ccbe6d1865d73c4a459945cd69899f8f</td>\n",
       "      <td>diff --git a/src/sqlfluff/cli/commands.py b/sr...</td>\n",
       "      <td>diff --git a/test/cli/commands_test.py b/test/...</td>\n",
       "      <td>Enable quiet mode/no-verbose in CLI for use in...</td>\n",
       "      <td></td>\n",
       "      <td>2023-04-16 14:24:42+00:00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>[test/cli/commands_test.py::test__cli__fix_mul...</td>\n",
       "      <td>[test/cli/commands_test.py::test__cli__command...</td>\n",
       "      <td>d19de0ecd16d298f9e3bfb91da122734c40c01e5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                repo              instance_id  \\\n",
       "0  sqlfluff/sqlfluff  sqlfluff__sqlfluff-4764   \n",
       "\n",
       "                                base_commit  \\\n",
       "0  a820c139ccbe6d1865d73c4a459945cd69899f8f   \n",
       "\n",
       "                                               patch  \\\n",
       "0  diff --git a/src/sqlfluff/cli/commands.py b/sr...   \n",
       "\n",
       "                                          test_patch  \\\n",
       "0  diff --git a/test/cli/commands_test.py b/test/...   \n",
       "\n",
       "                                   problem_statement hints_text  \\\n",
       "0  Enable quiet mode/no-verbose in CLI for use in...              \n",
       "\n",
       "                 created_at  version  \\\n",
       "0 2023-04-16 14:24:42+00:00      1.4   \n",
       "\n",
       "                                        FAIL_TO_PASS  \\\n",
       "0  [test/cli/commands_test.py::test__cli__fix_mul...   \n",
       "\n",
       "                                        PASS_TO_PASS  \\\n",
       "0  [test/cli/commands_test.py::test__cli__command...   \n",
       "\n",
       "                   environment_setup_commit  \n",
       "0  d19de0ecd16d298f9e3bfb91da122734c40c01e5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2caa6e13-eb36-46b1-99eb-1120ddf218e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this we will use a list of dictionaries with the keys named above.\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999edc7-0d2b-4c6c-b55f-2dcf19ce7ed9",
   "metadata": {},
   "source": [
    "# Generating our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7884052-eba6-4753-95dd-c722d0bba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_Stub():\n",
    "    def __init__(self):\n",
    "        self.name = \"stub\"\n",
    "\n",
    "    def predict(self, input: str):\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM_Stub()\n",
    "\n",
    "# Generating out solution\n",
    "for index, row in df.iterrows():\n",
    "    predict = llm.predict(row[\"problem_statement\"])\n",
    "    predictions.append({\n",
    "        \"instance_id\": row[\"instance_id\"],\n",
    "        \"model_patch\": predict,\n",
    "        \"model_name_or_path\": llm.name\n",
    "                       }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258df78-0b50-4527-892a-3c0e367c1263",
   "metadata": {},
   "source": [
    "# Saving our data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0e2a61b-87d8-4e2e-908a-3fa788ad314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a JSON formatted string\n",
    "json_data = json.dumps(predictions, indent=4)\n",
    "\n",
    "# Save the JSON string to a file\n",
    "with open('predictions.json', 'w') as json_file:\n",
    "    json_file.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb1612-8600-49c7-ab21-1f013afab45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
