{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import git\n",
    "import os\n",
    "import validators\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {},
   "source": [
    "# Evaluating the LLM-Agen on SWE-Benchmark\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-dev-dataset.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"SWEBench/swe-bench-dev-dataset.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41741fe9-a4d4-4f56-8f5c-cd0148ee7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                                                        sqlfluff/sqlfluff\n",
       "instance_id                                           sqlfluff__sqlfluff-4764\n",
       "base_commit                          a820c139ccbe6d1865d73c4a459945cd69899f8f\n",
       "patch                       diff --git a/src/sqlfluff/cli/commands.py b/sr...\n",
       "test_patch                  diff --git a/test/cli/commands_test.py b/test/...\n",
       "problem_statement           Enable quiet mode/no-verbose in CLI for use in...\n",
       "hints_text                                                                   \n",
       "created_at                                          2023-04-16 14:24:42+00:00\n",
       "version                                                                   1.4\n",
       "FAIL_TO_PASS                [test/cli/commands_test.py::test__cli__fix_mul...\n",
       "PASS_TO_PASS                [test/cli/commands_test.py::test__cli__command...\n",
       "environment_setup_commit             d19de0ecd16d298f9e3bfb91da122734c40c01e5\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999edc7-0d2b-4c6c-b55f-2dcf19ce7ed9",
   "metadata": {},
   "source": [
    "# Generating our Predictions\n",
    "\n",
    "## Defining the AgentWrapper\n",
    "\n",
    "We first define an `AgentWrapper` which job it is to:\n",
    "- clone the repos, set the head to the correct commit.\n",
    "- Calls our internal Agent, which does the changes.\n",
    "- Stages our changes.\n",
    "- Calculates the git diff, which we return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7884052-eba6-4753-95dd-c722d0bba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentStub():\n",
    "    def __init__(self,  start_cwd):\n",
    "         self.start_cwd =  start_cwd\n",
    "\n",
    "    def __call__(self, userprompt):\n",
    "        new_file = os.path.join(self.start_cwd, 'test_file.md')\n",
    "        \n",
    "        fp = open(new_file, 'w+')\n",
    "        fp.write('This is a test file, which test if the git diff gets caluclated correctly.')\n",
    "        fp.close()\n",
    "        \n",
    "        return \"\"\n",
    "\n",
    "class AgentWrapper():\n",
    "    def __init__(self, agent, name, working_directory=\"repos\", logging=True):\n",
    "        self.name = name\n",
    "        self.working_directory = working_directory\n",
    "        self.agent = agent\n",
    "        self.logging_enabled = logging\n",
    "\n",
    "        if not os.path.isdir(working_directory):\n",
    "            os.makedirs(working_directory)\n",
    "\n",
    "    def predict(self, row_input: Series):\n",
    "        repo_dir = self._clone_repo(row_input[\"repo\"], row_input[\"base_commit\"])\n",
    "        \n",
    "        result = self.agent(\"Question: \" + str(df.iloc[0][\"problem_statement\"]))\n",
    "        \n",
    "        if self.logging_enabled:\n",
    "            print(\"LOGGING: Finished the Agent with the following as return: \" + str(result))\n",
    "        repo = git.Repo(repo_dir)\n",
    "        repo.git.add(\"*\")\n",
    "        \n",
    "        diff = repo.git.diff(\"--cached\")\n",
    "        \n",
    "        if self.logging_enabled:\n",
    "            print(\"LOGGING: Finished caculating the git diff.\")\n",
    "            if diff == '': print(\"LOGGING: Git Diff is empty.\")\n",
    "        \n",
    "        return diff\n",
    "\n",
    "    def _clone_repo(self, repo_name: str, base_commit: str, overwrite_cloned_repo : bool = True):\n",
    "        repo_url = \"https://github.com/\" + repo_name\n",
    "        repo_dir = os.path.join(self.working_directory, repo_name.split('/', 1)[1])\n",
    "        \n",
    "        if not validators.url(repo_url):\n",
    "            raise Exception(\"The Repo url is not valid: \" + repo_url)\n",
    "                    \n",
    "        if not (os.path.isdir(repo_dir)) or (overwrite_cloned_repo):\n",
    "            if os.path.exists(repo_dir):\n",
    "                shutil.rmtree(repo_dir)\n",
    "            os.makedirs(repo_dir)\n",
    "\n",
    "            # clones the repo on which llm will work\n",
    "            git.Repo.clone_from(repo_url, repo_dir)\n",
    "\n",
    "        if self.logging_enabled:\n",
    "            print(\"LOGGING: Repo \" + str(repo_url) + \"downloaded in folder `\" + str(repo_dir) + \"`.\")\n",
    "            \n",
    "        # we need to make sure we have the correct commit stage\n",
    "        repo = git.Repo(repo_dir)\n",
    "        repo.git.reset('--hard', base_commit)\n",
    "\n",
    "        if self.logging_enabled:\n",
    "            print(\"LOGGING: Reset Git repo to the commit \" + str(base_commit))\n",
    "        \n",
    "        return repo_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8f0c4-11cb-4a22-8bea-1598c434ca56",
   "metadata": {},
   "source": [
    "## Testing AgentWrapper\n",
    "\n",
    "Testing that the cloning mechanism for repos and checking out the correct git commit is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09db429b-8ea5-4d23-9760-52efd84c464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a820c139ccbe6d1865d73c4a459945cd69899f8f'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"base_commit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17212c24-03a6-4690-b1e4-921e68c5254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stub\n",
      "----------------\n",
      "LOGGING: Repo https://github.com/sqlfluff/sqlfluffdownloaded in folder `repos/sqlfluff`.\n",
      "LOGGING: Reset Git repo to the commit a820c139ccbe6d1865d73c4a459945cd69899f8f\n",
      "LOGGING: Finished the Agent with the following as return: \n",
      "LOGGING: Finished caculating the git diff.\n",
      "LOGGING: Git Diff is empty.\n",
      "RESULT: \n"
     ]
    }
   ],
   "source": [
    "stub = AgentStub(\"repos\")\n",
    "agent = AgentWrapper(stub, \"stub\")\n",
    "\n",
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(\"RESULT: \" + str(agent.predict(df.iloc[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a82b1-185c-4b45-aad8-ed0efb059b5d",
   "metadata": {},
   "source": [
    "# Testing SmolCoder\n",
    "\n",
    "This requires starting the `phi3:latest` model, with ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a127113-b474-4e59-93f9-bb9c8f1ba82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lupos/miniconda3/envs/llm/lib/python311.zip', '/home/lupos/miniconda3/envs/llm/lib/python3.11', '/home/lupos/miniconda3/envs/llm/lib/python3.11/lib-dynload', '', '/home/lupos/miniconda3/envs/llm/lib/python3.11/site-packages', '/home/lupos/interactive-learning/SmolCoder']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(str(os.path.abspath('SmolCoder')))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14072627-c353-4ee3-aaab-41fb32758e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.replace_method import ReplaceMethod\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.tools.execute_python import ExecutePythonCode\n",
    "from SmolCoder.src.tools.show_method import ShowMethodBody\n",
    "from SmolCoder.src.tools.move_folder import MoveFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237bac3c-59a8-4d40-ab75-0cc06c999082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definition\n",
    "class_sumary = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "replace_method = ReplaceMethod()\n",
    "finish = Finish()\n",
    "execute_python = ExecutePythonCode()\n",
    "show_method = ShowMethodBody()\n",
    "move_folder = MoveFolder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8b706-bc7f-486b-8f55-63d47f19e693",
   "metadata": {},
   "source": [
    "## Testing Execute Python Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5b0734-bc24-40ff-9c95-6fd82f88d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Toolkit([execute_python])\n",
    "\n",
    "model = LLM(\"llama3:instruct\")\n",
    "smolCoder = SmolCoder(model, Path(\"tests/test_codebase\"), tools, mode=1)\n",
    "agent = AgentWrapper(smolCoder, \"smolecoder\")\n",
    "\n",
    "prompt = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0103363a-f353-4b72-9d19-ee9959167721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = agent.predict(prompt)\n",
    "#print(\"RESULT: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94d05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(smolCoder.inspect_history(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78b30-5c0e-49c3-b605-366f1eb6f287",
   "metadata": {},
   "source": [
    "# SmolCoder on SWE\n",
    "\n",
    "This tests SmolCoder on a single Instance of the SWE-Benchmark.\n",
    "This is without first trying to reproduce the bug, just barebones ReAct with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74e473e-0e6b-4b57-a3b1-ed9c97686331",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = Toolkit([list_files, move_folder, list_classes, class_sumary, show_method, replace_method, finish])\n",
    "\n",
    "model = LLM(\"phi3:latest\")\n",
    "smol_coder = SmolCoder(model, Path(\"repos\"), toolkit=toolkit, mode=0)\n",
    "\n",
    "agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f9919-5077-45cd-8768-a8d96b6aa8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmolCoder\n",
      "----------------\n",
      "LOGGING: Repo https://github.com/sqlfluff/sqlfluffdownloaded in folder `repos/sqlfluff`.\n",
      "LOGGING: Reset Git repo to the commit a820c139ccbe6d1865d73c4a459945cd69899f8f\n"
     ]
    }
   ],
   "source": [
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19c91e-3fc0-471a-a479-c5bff68803fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(smol_coder.inspect_history(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6494f-e13c-4e01-a860-86a8af311e54",
   "metadata": {},
   "source": [
    "## Generating all Predictions\n",
    "\n",
    "When running this on a server, it could happen that something crashed or an error is thrown which doesn't get catches, as such it is important to write the changes to disk for each entry in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation uses checkpoints, this means if the program \n",
    "# is interuppted it can start again, where it left oft.\n",
    "\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "#tools = Toolkit([class_sumary, list_classes, list_files, finish])\n",
    "#model = LLM(\"phi3:latest\")\n",
    "#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\n",
    "#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\n",
    "\n",
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "checkpoint_file = 'checkpoint.txt'\n",
    "resume_index = 0\n",
    "\n",
    "activated = 1\n",
    "\n",
    "if activated:\n",
    "    # Check if checkpoint file exists and read the last processed index\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            resume_index = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint file: {e}\")\n",
    "    \n",
    "    if resume_index < len(df) - 1:\n",
    "        # Open a file to save predictions\n",
    "        with open('predictions.json', 'a', encoding=\"utf-8-sig\") as json_file:\n",
    "            if resume_index == 0:\n",
    "                json_file.write('[')  # Start of JSON array\n",
    "                json_file.write('\\n')\n",
    "            # Generating our solution\n",
    "            for index, row in df.iterrows():\n",
    "                if index % 10 == 0: print(\"Current idx: \" + str(index))\n",
    "                # Skip rows that were already processed\n",
    "                if index < resume_index:\n",
    "                    continue\n",
    "        \n",
    "                predictions = {\n",
    "                    \"instance_id\": row[\"instance_id\"],\n",
    "                    \"model_patch\": agent.predict(row),\n",
    "                    \"model_name_or_path\": agent.name\n",
    "                }\n",
    "                # Convert the dictionary to a JSON formatted string and write to file\n",
    "                json_data = json.dumps(predictions, indent=4)\n",
    "                json_file.write(json_data)\n",
    "                if index < len(df) - 1:\n",
    "                    json_file.write(',')\n",
    "                json_file.write('\\n')\n",
    "        \n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    f.write(str(index))\n",
    "                    \n",
    "            if index == len(df) - 1:\n",
    "                json_file.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ff1e1",
   "metadata": {},
   "source": [
    "# Meta Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.prompting_strategy import PromptingStrategy\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.meta_tokenizer import MetaTokenizer\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "\n",
    "list_methods = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "finish = Finish()\n",
    "\n",
    "toolkit = Toolkit([list_methods, list_classes, list_files, finish])\n",
    "\n",
    "smol = SmolCoder(model=LLM(\"phi3:latest\"), codebase_dir= Path(\"test_codebase/\"), toolkit=toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "smol(\"Question: What methods do the classes in test.py have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5ce37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486fc9e-e79f-4279-8ba8-e21d4768bedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
