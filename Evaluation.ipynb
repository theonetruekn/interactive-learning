{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f75dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {},
   "source": [
    "# Evaluating the LLM-Agen on SWE-Benchmark\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-lite.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41741fe9-a4d4-4f56-8f5c-cd0148ee7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                                                        sqlfluff/sqlfluff\n",
       "instance_id                                           sqlfluff__sqlfluff-2862\n",
       "base_commit                          447ecf862a4d2b977d0add9f444655357b9c4f1f\n",
       "patch                       diff --git a/src/sqlfluff/core/linter/common.p...\n",
       "test_patch                  diff --git a/test/api/simple_test.py b/test/ap...\n",
       "problem_statement           fix keep adding new line on wrong place \\n### ...\n",
       "hints_text                  > Version\\r\\n> sqlfluff, version 0.6.2\\r\\n\\r\\n...\n",
       "created_at                                          2022-03-14 19:46:08+00:00\n",
       "version                                                                   0.1\n",
       "FAIL_TO_PASS                [test/api/simple_test.py::test__api__lint_stri...\n",
       "PASS_TO_PASS                [test/api/simple_test.py::test__api__lint_stri...\n",
       "environment_setup_commit             3d52e8270d82aeccf4c516d059a80a6947919aea\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a82b1-185c-4b45-aad8-ed0efb059b5d",
   "metadata": {},
   "source": [
    "# Testing SmolCoder\n",
    "\n",
    "This requires starting the `phi3:latest` model, with ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a127113-b474-4e59-93f9-bb9c8f1ba82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lupos/Agentless', '/home/lupos/miniconda3/envs/llm/lib/python311.zip', '/home/lupos/miniconda3/envs/llm/lib/python3.11', '/home/lupos/miniconda3/envs/llm/lib/python3.11/lib-dynload', '', '/home/lupos/miniconda3/envs/llm/lib/python3.11/site-packages', '/home/lupos/interactive-learning/SmolCoder']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(str(os.path.abspath('SmolCoder')))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14072627-c353-4ee3-aaab-41fb32758e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "from SmolCoder.src.agent_wrapper import AgentWrapper\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.replace_method import ReplaceMethod\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.tools.execute_python import ExecutePythonCode\n",
    "from SmolCoder.src.tools.show_method import ShowMethodBody\n",
    "from SmolCoder.src.tools.move_folder import MoveFolder\n",
    "from SmolCoder.src.tools.human_interaction import HumanInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237bac3c-59a8-4d40-ab75-0cc06c999082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definition\n",
    "class_sumary = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "replace_method = ReplaceMethod()\n",
    "finish = Finish()\n",
    "execute_python = ExecutePythonCode()\n",
    "show_method = ShowMethodBody()\n",
    "move_folder = MoveFolder()\n",
    "human_interaction = HumanInteraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8b706-bc7f-486b-8f55-63d47f19e693",
   "metadata": {},
   "source": [
    "## Testing Execute Python Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5b0734-bc24-40ff-9c95-6fd82f88d021",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tools \u001b[38;5;241m=\u001b[39m Toolkit([execute_python])\n\u001b[0;32m----> 3\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "tools = Toolkit([execute_python])\n",
    "\n",
    "agent = AgentWrapper(agent_name=\"SmolCoder\",\n",
    "                     toolkit=tools,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "prompt = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0103363a-f353-4b72-9d19-ee9959167721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = agent.predict(prompt)\n",
    "#print(\"RESULT: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94d05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(smolCoder.inspect_history(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78b30-5c0e-49c3-b605-366f1eb6f287",
   "metadata": {},
   "source": [
    "# SmolCoder on SWE\n",
    "\n",
    "This tests SmolCoder on a single Instance of the SWE-Benchmark.\n",
    "This is without first trying to reproduce the bug, just barebones ReAct with tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74e473e-0e6b-4b57-a3b1-ed9c97686331",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3f9919-5077-45cd-8768-a8d96b6aa8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mpredict(df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc19c91e-3fc0-471a-a479-c5bff68803fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6494f-e13c-4e01-a860-86a8af311e54",
   "metadata": {},
   "source": [
    "## Generating all Predictions\n",
    "\n",
    "When running this on a server, it could happen that something crashed or an error is thrown which doesn't get catches, as such it is important to write the changes to disk for each entry in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentStub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#tools = Toolkit([class_sumary, list_classes, list_files, finish])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#model = LLM(\"phi3:latest\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m stub \u001b[38;5;241m=\u001b[39m \u001b[43mAgentStub\u001b[49m()\n\u001b[1;32m     13\u001b[0m agent \u001b[38;5;241m=\u001b[39m AgentWrapper(stub, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m checkpoint_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AgentStub' is not defined"
     ]
    }
   ],
   "source": [
    "# This implementation uses checkpoints, this means if the program \n",
    "# is interuppted it can start again, where it left oft.\n",
    "\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "#tools = Toolkit([class_sumary, list_classes, list_files, finish])\n",
    "#model = LLM(\"phi3:latest\")\n",
    "#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\n",
    "#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\n",
    "\n",
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "checkpoint_file = 'checkpoint.txt'\n",
    "resume_index = 0\n",
    "\n",
    "activated = 1\n",
    "\n",
    "if activated:\n",
    "    # Check if checkpoint file exists and read the last processed index\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            resume_index = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint file: {e}\")\n",
    "    \n",
    "    if resume_index < len(df) - 1:\n",
    "        # Open a file to save predictions\n",
    "        with open('predictions.json', 'a', encoding=\"utf-8-sig\") as json_file:\n",
    "            if resume_index == 0:\n",
    "                json_file.write('[')  # Start of JSON array\n",
    "                json_file.write('\\n')\n",
    "            # Generating our solution\n",
    "            for index, row in df.iterrows():\n",
    "                if index % 10 == 0: print(\"Current idx: \" + str(index))\n",
    "                # Skip rows that were already processed\n",
    "                if index < resume_index:\n",
    "                    continue\n",
    "        \n",
    "                predictions = {\n",
    "                    \"instance_id\": row[\"instance_id\"],\n",
    "                    \"model_patch\": agent.predict(row),\n",
    "                    \"model_name_or_path\": agent.name\n",
    "                }\n",
    "                # Convert the dictionary to a JSON formatted string and write to file\n",
    "                json_data = json.dumps(predictions, indent=4)\n",
    "                json_file.write(json_data)\n",
    "                if index < len(df) - 1:\n",
    "                    json_file.write(',')\n",
    "                json_file.write('\\n')\n",
    "        \n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    f.write(str(index))\n",
    "                    \n",
    "            if index == len(df) - 1:\n",
    "                json_file.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ff1e1",
   "metadata": {},
   "source": [
    "# Meta Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95cbbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.prompting_strategy import PromptingStrategy\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.meta_tokenizer import MetaTokenizer\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()\n",
    "\n",
    "list_methods = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "finish = Finish()\n",
    "\n",
    "toolkit = Toolkit([list_methods, list_classes, list_files, finish])\n",
    "\n",
    "smol = SmolCoder(phase=3, model=LLM(\"llama3.1\", openai=[False, \"None\"], logger=None), codebase_dir= Path(\"test_codebase/\"), logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31b2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUS CODE SNIPPET PHASE: \n",
      "\n",
      "\n",
      "Error while extracting code for function '_iter_segments' in file './repos/sqlfluff/src/sqlfluff/core/parser/lexer.py'\n",
      "Error while extracting code for function '_handle_zero_length_slice' in file './repos/sqlfluff/src/sqlfluff/core/parser/lexer.py'\n",
      "Error while extracting code for class 'BlockTracker' in file './repos/sqlfluff/src/sqlfluff/core/parser/lexer.py'\n",
      "You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is, to solve this issue. First you will be given a tree structure of the codebase, your task is it based on the description of the issue to select relevant files of it for closer inspection. After this you will be provided with a skeleten for each of your slected file, this skeleton will consist out of class and method headers and your task will be to select the classes and methods that are relevant to the described issue. At the end you will be provided with the source code of your selected classes and methos and asked to fix it.\n",
      "--------------------------------------------\n",
      "You will now be given the description of the GitHub Issue: \n",
      "\n",
      "Enable quiet mode/no-verbose in CLI for use in pre-commit hook\n",
      "There seems to be only an option to increase the level of verbosity when using SQLFluff [CLI](https://docs.sqlfluff.com/en/stable/cli.html), not to limit it further.\n",
      "\n",
      "It would be great to have an option to further limit the amount of prints when running `sqlfluff fix`, especially in combination with deployment using a pre-commit hook. For example, only print the return status and the number of fixes applied, similar to how it is when using `black` in a pre-commit hook:\n",
      "![image](https://user-images.githubusercontent.com/10177212/140480676-dc98d00b-4383-44f2-bb90-3301a6eedec2.png)\n",
      "\n",
      "This hides the potentially long list of fixes that are being applied to the SQL files, which can get quite verbose.\n",
      "\n",
      "--------------------------------------------\n",
      "We now want to identify whether the following code snippet is relevant to the described issue.\n",
      "You will be provided with a source code snippet. You should decide whether it is relevant to the issue.\n",
      "Please respond with either 'YES.' or 'NO.'.\n",
      "Example Answer:\n",
      "YES.--------------------------------------------\n",
      "Here is the code snippet:\n",
      "class Lexer:\n",
      "    \"\"\"The Lexer class actually does the lexing step.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        config: Optional[FluffConfig] = None,\n",
      "        last_resort_lexer: Optional[StringLexer] = None,\n",
      "        dialect: Optional[str] = None,\n",
      "    ):\n",
      "        # Allow optional config and dialect\n",
      "        self.config = FluffConfig.from_kwargs(config=config, dialect=dialect)\n",
      "        # Store the matchers\n",
      "        self.lexer_matchers = self.config.get(\"dialect_obj\").get_lexer_matchers()\n",
      "\n",
      "        self.last_resort_lexer = last_resort_lexer or RegexLexer(\n",
      "            \"<unlexable>\",\n",
      "            r\"[^\\t\\n\\,\\.\\ \\-\\+\\*\\\\\\/\\'\\\"\\;\\:\\[\\]\\(\\)\\|]*\",\n",
      "            UnlexableSegment,\n",
      "        )\n",
      "\n",
      "    def lex(\n",
      "        self, raw: Union[str, TemplatedFile]\n",
      "    ) -> Tuple[Tuple[BaseSegment, ...], List[SQLLexError]]:\n",
      "        \"\"\"Take a string or TemplatedFile and return segments.\n",
      "\n",
      "        If we fail to match the *whole* string, then we must have\n",
      "        found something that we cannot lex. If that happens we should\n",
      "        package it up as unlexable and keep track of the exceptions.\n",
      "        \"\"\"\n",
      "        # Make sure we've got a string buffer and a template\n",
      "        # regardless of what was passed in.\n",
      "        if isinstance(raw, str):\n",
      "            template = TemplatedFile.from_string(raw)\n",
      "            str_buff = raw\n",
      "        else:\n",
      "            template = raw\n",
      "            str_buff = str(template)\n",
      "\n",
      "        # Lex the string to get a tuple of LexedElement\n",
      "        element_buffer: List[LexedElement] = []\n",
      "        while True:\n",
      "            res = self.lex_match(str_buff, self.lexer_matchers)\n",
      "            element_buffer += res.elements\n",
      "            if res.forward_string:\n",
      "                resort_res = self.last_resort_lexer.match(res.forward_string)\n",
      "                if not resort_res:\n",
      "                    # If we STILL can't match, then just panic out.\n",
      "                    raise SQLLexError(\n",
      "                        f\"Fatal. Unable to lex characters: {0!r}\".format(\n",
      "                            res.forward_string[:10] + \"...\"\n",
      "                            if len(res.forward_string) > 9\n",
      "                            else res.forward_string\n",
      "                        )\n",
      "                    )\n",
      "                str_buff = resort_res.forward_string\n",
      "                element_buffer += resort_res.elements\n",
      "            else:  # pragma: no cover TODO?\n",
      "                break\n",
      "\n",
      "        # Map tuple LexedElement to list of TemplateElement.\n",
      "        # This adds the template_slice to the object.\n",
      "        templated_buffer = self.map_template_slices(element_buffer, template)\n",
      "\n",
      "        # Turn lexed elements into segments.\n",
      "        segments: Tuple[RawSegment, ...] = self.elements_to_segments(\n",
      "            templated_buffer, template\n",
      "        )\n",
      "\n",
      "        # Generate any violations\n",
      "        violations: List[SQLLexError] = self.violations_from_segments(segments)\n",
      "\n",
      "        return segments, violations\n",
      "\n",
      "    def elements_to_segments(\n",
      "        self, elements: List[TemplateElement], templated_file: TemplatedFile\n",
      "    ) -> Tuple[RawSegment, ...]:\n",
      "        \"\"\"Convert a tuple of lexed elements into a tuple of segments.\"\"\"\n",
      "        # Working buffer to build up segments\n",
      "        segment_buffer: List[RawSegment] = []\n",
      "\n",
      "        lexer_logger.info(\"Elements to Segments.\")\n",
      "        # Get the templated slices to re-insert tokens for them\n",
      "        source_only_slices = templated_file.source_only_slices()\n",
      "        lexer_logger.info(\"Source-only slices: %s\", source_only_slices)\n",
      "        stash_source_slice, last_source_slice = None, None\n",
      "\n",
      "        # Now work out source slices, and add in template placeholders.\n",
      "        for idx, element in enumerate(elements):\n",
      "            # Calculate Source Slice\n",
      "            if idx != 0:\n",
      "                last_source_slice = stash_source_slice\n",
      "            source_slice = templated_file.templated_slice_to_source_slice(\n",
      "                element.template_slice\n",
      "            )\n",
      "            stash_source_slice = source_slice\n",
      "            # Output the slice as we lex.\n",
      "            lexer_logger.debug(\n",
      "                \"  %s, %s, %s, %r\",\n",
      "                idx,\n",
      "                element,\n",
      "                source_slice,\n",
      "                templated_file.templated_str[element.template_slice],\n",
      "            )\n",
      "\n",
      "            # The calculated source slice will include any source only slices.\n",
      "            # We should consider all of them in turn to see whether we can\n",
      "            # insert them.\n",
      "            so_slices = []\n",
      "            # Only look for source only slices if we've got a new source slice to\n",
      "            # avoid unnecessary duplication.\n",
      "            if last_source_slice != source_slice:\n",
      "                for source_only_slice in source_only_slices:\n",
      "                    # If it's later in the source, stop looking. Any later\n",
      "                    # ones *also* won't match.\n",
      "                    if source_only_slice.source_idx >= source_slice.stop:\n",
      "                        break\n",
      "                    elif source_only_slice.source_idx >= source_slice.start:\n",
      "                        so_slices.append(source_only_slice)\n",
      "\n",
      "            if so_slices:\n",
      "                lexer_logger.debug(\"    Collected Source Only Slices\")\n",
      "                for so_slice in so_slices:\n",
      "                    lexer_logger.debug(\"       %s\", so_slice)\n",
      "\n",
      "                # Calculate some things which will be useful\n",
      "                templ_str = templated_file.templated_str[element.template_slice]\n",
      "                source_str = templated_file.source_str[source_slice]\n",
      "\n",
      "                # For reasons which aren't entirely clear right now, if there is\n",
      "                # an included literal, it will always be at the end. Let's see if it's\n",
      "                # there.\n",
      "                if source_str.endswith(templ_str):\n",
      "                    existing_len = len(templ_str)\n",
      "                else:\n",
      "                    existing_len = 0\n",
      "\n",
      "                # Calculate slices\n",
      "                placeholder_slice = slice(\n",
      "                    source_slice.start, source_slice.stop - existing_len\n",
      "                )\n",
      "                placeholder_str = source_str[:-existing_len]\n",
      "                source_slice = slice(\n",
      "                    source_slice.stop - existing_len, source_slice.stop\n",
      "                )\n",
      "                # If it doesn't manage to extract a placeholder string from the source\n",
      "                # just concatenate the source only strings. There is almost always\n",
      "                # only one of them.\n",
      "                if not placeholder_str:\n",
      "                    placeholder_str = \"\".join(s.raw for s in so_slices)\n",
      "                # The Jinja templater sometimes returns source-only slices with\n",
      "                # gaps between. For example, in this section:\n",
      "                #\n",
      "                #   {% else %}\n",
      "                #   JOIN\n",
      "                #       {{action}}_raw_effect_sizes\n",
      "                #   USING\n",
      "                #       ({{ states }})\n",
      "                #   {% endif %}\n",
      "                #\n",
      "                # we might get {% else %} and {% endif %} slices, without the\n",
      "                # 4 lines between. This indicates those lines were not executed\n",
      "                # In this case, generate a placeholder where the skipped code is\n",
      "                # omitted but noted with a brief string, e.g.:\n",
      "                #\n",
      "                # \"{% else %}... [103 unused template characters] ...{% endif %}\".\n",
      "                #\n",
      "                # This is more readable -- it would be REALLY confusing for a\n",
      "                # placeholder to include code that wasn't even executed!!\n",
      "                if len(so_slices) >= 2:\n",
      "                    has_gap = False\n",
      "                    gap_placeholder_parts = []\n",
      "                    last_slice = None\n",
      "                    # For each slice...\n",
      "                    for so_slice in so_slices:\n",
      "                        # If it's not the first slice, was there a gap?\n",
      "                        if last_slice:\n",
      "                            end_last = last_slice.source_idx + len(last_slice.raw)\n",
      "                            chars_skipped = so_slice.source_idx - end_last\n",
      "                            if chars_skipped:\n",
      "                                # Yes, gap between last_slice and so_slice.\n",
      "                                has_gap = True\n",
      "\n",
      "                                # Generate a string documenting the gap.\n",
      "                                if chars_skipped >= 10:\n",
      "                                    gap_placeholder_parts.append(\n",
      "                                        f\"... [{chars_skipped} unused template characters] ...\"\n",
      "                                    )\n",
      "                                else:\n",
      "                                    gap_placeholder_parts.append(\"...\")\n",
      "                        # Now add the slice's source.\n",
      "                        gap_placeholder_parts.append(so_slice.raw)\n",
      "                        last_slice = so_slice\n",
      "                    if has_gap:\n",
      "                        placeholder_str = \"\".join(gap_placeholder_parts)\n",
      "                lexer_logger.debug(\n",
      "                    \"    Overlap Length: %s. PS: %s, LS: %s, p_str: %r, templ_str: %r\",\n",
      "                    existing_len,\n",
      "                    placeholder_slice,\n",
      "                    source_slice,\n",
      "                    placeholder_str,\n",
      "                    templ_str,\n",
      "                )\n",
      "\n",
      "                # Calculate potential indent/dedent\n",
      "                block_slices = sum(s.slice_type.startswith(\"block_\") for s in so_slices)\n",
      "                block_balance = sum(\n",
      "                    s.slice_type == \"block_start\" for s in so_slices\n",
      "                ) - sum(s.slice_type == \"block_end\" for s in so_slices)\n",
      "                lead_dedent = so_slices[0].slice_type in (\"block_end\", \"block_mid\")\n",
      "                trail_indent = so_slices[-1].slice_type in (\"block_start\", \"block_mid\")\n",
      "                add_indents = self.config.get(\"template_blocks_indent\", \"indentation\")\n",
      "                lexer_logger.debug(\n",
      "                    \"    Block Slices: %s. Block Balance: %s. Lead: %s, Trail: %s, Add: %s\",\n",
      "                    block_slices,\n",
      "                    block_balance,\n",
      "                    lead_dedent,\n",
      "                    trail_indent,\n",
      "                    add_indents,\n",
      "                )\n",
      "\n",
      "                # Add a dedent if appropriate.\n",
      "                if lead_dedent and add_indents:\n",
      "                    lexer_logger.debug(\"      DEDENT\")\n",
      "                    segment_buffer.append(\n",
      "                        Dedent(\n",
      "                            pos_marker=PositionMarker.from_point(\n",
      "                                placeholder_slice.start,\n",
      "                                element.template_slice.start,\n",
      "                                templated_file,\n",
      "                            )\n",
      "                        )\n",
      "                    )\n",
      "\n",
      "                # Always add a placeholder\n",
      "                segment_buffer.append(\n",
      "                    TemplateSegment(\n",
      "                        pos_marker=PositionMarker(\n",
      "                            placeholder_slice,\n",
      "                            slice(\n",
      "                                element.template_slice.start,\n",
      "                                element.template_slice.start,\n",
      "                            ),\n",
      "                            templated_file,\n",
      "                        ),\n",
      "                        source_str=placeholder_str,\n",
      "                        block_type=so_slices[0].slice_type\n",
      "                        if len(so_slices) == 1\n",
      "                        else \"compound\",\n",
      "                    )\n",
      "                )\n",
      "                lexer_logger.debug(\n",
      "                    \"      Placeholder: %s, %r\", segment_buffer[-1], placeholder_str\n",
      "                )\n",
      "\n",
      "                # Add an indent if appropriate.\n",
      "                if trail_indent and add_indents:\n",
      "                    lexer_logger.debug(\"      INDENT\")\n",
      "                    segment_buffer.append(\n",
      "                        Indent(\n",
      "                            is_template=True,\n",
      "                            pos_marker=PositionMarker.from_point(\n",
      "                                placeholder_slice.stop,\n",
      "                                element.template_slice.start,\n",
      "                                templated_file,\n",
      "                            ),\n",
      "                        )\n",
      "                    )\n",
      "\n",
      "            # Add the actual segment\n",
      "            segment_buffer.append(\n",
      "                element.to_segment(\n",
      "                    pos_marker=PositionMarker(\n",
      "                        source_slice,\n",
      "                        element.template_slice,\n",
      "                        templated_file,\n",
      "                    ),\n",
      "                )\n",
      "            )\n",
      "\n",
      "        # Convert to tuple before return\n",
      "        return tuple(segment_buffer)\n",
      "\n",
      "    @staticmethod\n",
      "    def violations_from_segments(segments: Tuple[RawSegment, ...]) -> List[SQLLexError]:\n",
      "        \"\"\"Generate any lexing errors for any unlexables.\"\"\"\n",
      "        violations = []\n",
      "        for segment in segments:\n",
      "            if segment.is_type(\"unlexable\"):\n",
      "                violations.append(\n",
      "                    SQLLexError(\n",
      "                        \"Unable to lex characters: {!r}\".format(\n",
      "                            segment.raw[:10] + \"...\"\n",
      "                            if len(segment.raw) > 9\n",
      "                            else segment.raw\n",
      "                        ),\n",
      "                        pos=segment.pos_marker,\n",
      "                    )\n",
      "                )\n",
      "        return violations\n",
      "\n",
      "    @staticmethod\n",
      "    def lex_match(forward_string: str, lexer_matchers: List[StringLexer]) -> LexMatch:\n",
      "        \"\"\"Iteratively match strings using the selection of submatchers.\"\"\"\n",
      "        elem_buff: List[LexedElement] = []\n",
      "        while True:\n",
      "            if len(forward_string) == 0:\n",
      "                return LexMatch(forward_string, elem_buff)\n",
      "            for matcher in lexer_matchers:\n",
      "                res = matcher.match(forward_string)\n",
      "                if res.elements:\n",
      "                    # If we have new segments then whoop!\n",
      "                    elem_buff += res.elements\n",
      "                    forward_string = res.forward_string\n",
      "                    # Cycle back around again and start with the top\n",
      "                    # matcher again.\n",
      "                    break\n",
      "            else:\n",
      "                # We've got so far, but now can't match. Return\n",
      "                return LexMatch(forward_string, elem_buff)\n",
      "\n",
      "    @staticmethod\n",
      "    def map_template_slices(\n",
      "        elements: List[LexedElement], template: TemplatedFile\n",
      "    ) -> List[TemplateElement]:\n",
      "        \"\"\"Create a tuple of TemplateElement from a tuple of LexedElement.\n",
      "\n",
      "        This adds slices in the templated file to the original lexed\n",
      "        elements. We'll need this to work out the position in the source\n",
      "        file.\n",
      "        \"\"\"\n",
      "        idx = 0\n",
      "        templated_buff: List[TemplateElement] = []\n",
      "        for element in elements:\n",
      "            template_slice = slice(idx, idx + len(element.raw))\n",
      "            idx += len(element.raw)\n",
      "            templated_buff.append(TemplateElement.from_element(element, template_slice))\n",
      "            if (\n",
      "                template.templated_str[template_slice] != element.raw\n",
      "            ):  # pragma: no cover\n",
      "                raise ValueError(\n",
      "                    \"Template and lexed elements do not match. This should never \"\n",
      "                    f\"happen {element.raw!r} != {template.templated_str[template_slice]!r}\"\n",
      "                )\n",
      "        return templated_buff\n",
      "--------------------------------------------\n",
      "Is this code snippet relevant to the issue? Please respond with 'YES.' or 'NO.'.\n",
      "\n",
      "(If it's too long, you can summarize its contents in a sentence or two)\n",
      "NO.\n",
      " NO.\n",
      "No relevant classes/functions were found.\n",
      "REPAIR PHASE:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smol(df.iloc[0][\"problem_statement\"], start_cwd=\"./repos/sqlfluff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c04035-61e5-4388-a860-8d0b3611e429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20db2d-09a7-46ca-bb99-0ba34b53fa79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
