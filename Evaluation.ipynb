{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import json\n",
    "import git\n",
    "import os\n",
    "import validators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {},
   "source": [
    "# Evaluating the LLM-Agen on SWE-Benchmark\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-dev-dataset.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"SWEBench/swe-bench-dev-dataset.json\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41741fe9-a4d4-4f56-8f5c-cd0148ee7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                                                        sqlfluff/sqlfluff\n",
       "instance_id                                           sqlfluff__sqlfluff-4764\n",
       "base_commit                          a820c139ccbe6d1865d73c4a459945cd69899f8f\n",
       "patch                       diff --git a/src/sqlfluff/cli/commands.py b/sr...\n",
       "test_patch                  diff --git a/test/cli/commands_test.py b/test/...\n",
       "problem_statement           Enable quiet mode/no-verbose in CLI for use in...\n",
       "hints_text                                                                   \n",
       "created_at                                          2023-04-16 14:24:42+00:00\n",
       "version                                                                   1.4\n",
       "FAIL_TO_PASS                [test/cli/commands_test.py::test__cli__fix_mul...\n",
       "PASS_TO_PASS                [test/cli/commands_test.py::test__cli__command...\n",
       "environment_setup_commit             d19de0ecd16d298f9e3bfb91da122734c40c01e5\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999edc7-0d2b-4c6c-b55f-2dcf19ce7ed9",
   "metadata": {},
   "source": [
    "# Generating our Predictions\n",
    "\n",
    "## Defining the AgentWrapper\n",
    "\n",
    "We first define an `AgentWrapper` which job it is to:\n",
    "- clone the repos, set the head to the correct commit.\n",
    "- Calls our internal Agent, which does the changes.\n",
    "- Stages our changes.\n",
    "- Calculates the git diff, which we return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7884052-eba6-4753-95dd-c722d0bba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentStub():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, row_input, repo_dir):\n",
    "        new_file = os.path.join(repo_dir, 'test_file.md')\n",
    "        \n",
    "        fp = open(new_file, 'w+')\n",
    "        fp.write('This is a test file, which test if the git diff gets caluclated correctly.')\n",
    "        fp.close()\n",
    "        \n",
    "        return \"\"\n",
    "\n",
    "class AgentWrapper():\n",
    "    def __init__(self, agent, working_directory=\"repos\"):\n",
    "        self.name = \"stub\"\n",
    "        self.working_directory = working_directory\n",
    "        self.agent = agent\n",
    "\n",
    "        if not os.path.isdir(working_directory):\n",
    "            os.makedirs(working_directory)\n",
    "\n",
    "    def predict(self, row_input: Series):\n",
    "        repo_dir = self._clone_repo(row_input[\"repo\"], row_input[\"base_commit\"])\n",
    "        \n",
    "        result = self.agent.predict(row_input, repo_dir)\n",
    "\n",
    "        repo = git.Repo(repo_dir)\n",
    "        repo.git.add(\"*\")\n",
    "        return repo.git.diff(\"--cached\")\n",
    "\n",
    "    def _clone_repo(self, repo_name: str, base_commit: str):\n",
    "        repo_url = \"https://github.com/\" + repo_name\n",
    "        repo_dir = os.path.join(self.working_directory, repo_name.split('/', 1)[1])\n",
    "        \n",
    "        if not validators.url(repo_url):\n",
    "            raise Exception(\"The Repo url is not valid: \" + repo_url)\n",
    "                    \n",
    "        if not os.path.isdir(repo_dir):\n",
    "            os.makedirs(repo_dir)\n",
    "\n",
    "            # clones the repo on which llm will work\n",
    "            git.Repo.clone_from(repo_url, repo_dir)\n",
    "        \n",
    "        # we need to make sure we have the correct commit stage\n",
    "        repo = git.Repo(repo_dir)\n",
    "        repo.git.reset('--hard', base_commit)\n",
    "\n",
    "        return repo_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8f0c4-11cb-4a22-8bea-1598c434ca56",
   "metadata": {},
   "source": [
    "## Testing AgentWrapper\n",
    "\n",
    "Testing that the cloning mechanism for repos and checking out the correct git commit is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09db429b-8ea5-4d23-9760-52efd84c464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a820c139ccbe6d1865d73c4a459945cd69899f8f'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"base_commit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17212c24-03a6-4690-b1e4-921e68c5254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stub\n",
      "----------------\n",
      "diff --git a/test_file.md b/test_file.md\n",
      "new file mode 100644\n",
      "index 000000000..76c846906\n",
      "--- /dev/null\n",
      "+++ b/test_file.md\n",
      "@@ -0,0 +1 @@\n",
      "+This is a test file, which test if the git diff gets caluclated correctly.\n",
      "\\ No newline at end of file\n"
     ]
    }
   ],
   "source": [
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6494f-e13c-4e01-a860-86a8af311e54",
   "metadata": {},
   "source": [
    "## Generating all Predictions\n",
    "\n",
    "When running this on a server, it could happen that something crashed or an error is thrown which doesn't get catches, as such it is important to write the changes to disk for each entry in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation uses checkpoints, this means if the program \n",
    "# is interuppted it can start again, where it left oft.\n",
    "\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "checkpoint_file = 'checkpoint.txt'\n",
    "resume_index = 0\n",
    "\n",
    "activated = 0\n",
    "\n",
    "if activated:\n",
    "    # Check if checkpoint file exists and read the last processed index\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            resume_index = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint file: {e}\")\n",
    "    \n",
    "    if resume_index < len(df) - 1:\n",
    "        # Open a file to save predictions\n",
    "        with open('predictions.json', 'a') as json_file:\n",
    "            if resume_index == 0:\n",
    "                json_file.write('[')  # Start of JSON array\n",
    "                json_file.write('\\n')\n",
    "            # Generating our solution\n",
    "            for index, row in df.iterrows():\n",
    "                # Skip rows that were already processed\n",
    "                if index < resume_index:\n",
    "                    continue\n",
    "        \n",
    "                predictions = {\n",
    "                    \"instance_id\": row[\"instance_id\"],\n",
    "                    \"model_patch\": agent.predict(row),\n",
    "                    \"model_name_or_path\": agent.name\n",
    "                }\n",
    "                # Convert the dictionary to a JSON formatted string and write to file\n",
    "                json_data = json.dumps(predictions, indent=4)\n",
    "                json_file.write(json_data)\n",
    "                if index < len(df) - 1:\n",
    "                    json_file.write(',')\n",
    "                json_file.write('\\n')\n",
    "        \n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    f.write(str(index))\n",
    "                    \n",
    "            if index == len(df) - 1:\n",
    "                json_file.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a82b1-185c-4b45-aad8-ed0efb059b5d",
   "metadata": {},
   "source": [
    "# Testing SmolCoder\n",
    "\n",
    "This requires starting the `phi3:latest` model, with ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a127113-b474-4e59-93f9-bb9c8f1ba82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lupos/miniconda3/envs/llm/lib/python311.zip', '/home/lupos/miniconda3/envs/llm/lib/python3.11', '/home/lupos/miniconda3/envs/llm/lib/python3.11/lib-dynload', '', '/home/lupos/miniconda3/envs/llm/lib/python3.11/site-packages', '/home/lupos/interactive-learning/SmolCoder']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(str(os.path.abspath('SmolCoder')))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14072627-c353-4ee3-aaab-41fb32758e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "\n",
    "from SmolCoder.src.tools.get_class_summary import GetClassSummary\n",
    "from SmolCoder.src.tools.list_classes import GetClassDocstrings\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.replace_method import ReplaceMethod\n",
    "from SmolCoder.src.tools.finish import Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237bac3c-59a8-4d40-ab75-0cc06c999082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definition\n",
    "class_sumary = GetClassSummary()\n",
    "list_classes = GetClassDocstrings()\n",
    "list_files = ListFiles()\n",
    "replace_method = ReplaceMethod()\n",
    "finish = Finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5b0734-bc24-40ff-9c95-6fd82f88d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Toolkit([class_sumary, list_classes, list_files, replace_method, finish])\n",
    "\n",
    "model = LLM(\"phi3:latest\")\n",
    "agent = SmolCoder(model, Path(\"tests/test_codebase\"), tools)\n",
    "\n",
    "prompt = \"Can you list me all functions in the test.py?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0103363a-f353-4b72-9d19-ee9959167721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Curren final prompt with llm response\n",
      "You will be given `question` and you will respond with `answer`.\n",
      "\n",
      "To do this, you will interleave Thought, Action, and Observation steps.\n",
      "\n",
      "Thought can reason about the current situation.\n",
      "Action can be the following types, \n",
      "(1) Get_Class_Summary[class_name], which returns a formatted string of methods heads from the class specified in `class_name`.\n",
      "(2) List_Classes[file_name], which lists all the class names and their docstring comments in the specified Python file.\n",
      "(3) List_Files[folder], which lists all the files and subfolder that are in the folder.\n",
      "(4) Replace_Method[class_name,method_name,new_method], which replaces the specified method `method_name` in the `class_name` with `new_method`.\n",
      "(5) Finish[answer], which finishes the program.\n",
      "Input variables of the tools do not need quotation marks around them.\n",
      "---\n",
      "\n",
      "Follow the following format:\n",
      "\n",
      "Thought: Reasoning which action to take to solve the task.\n",
      "Action: Always either Get_Class_Summary[class_name] or List_Classes[file_name] or List_Files[folder] or Replace_Method[class_name,method_name,new_method] or Finish[answer]\n",
      "Observation: result of the previous Action\n",
      "Thought: next steps to take based on the previous Observation\n",
      "...\n",
      "until Action is of type `Finish`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you list me all functions in the test.py?\n",
      " Thought: To answer the question, I need to find out which classes and methods are present in the 'test.py' file, specifically focusing on function definitions.\n",
      "\n",
      "Action: List_Classes[test.py]\n",
      "\n",
      "Observation\n",
      "-------------------------------------------------\n",
      "Toolname: List_Classes, Args: ['test.py']\n",
      "Querying list_classes\n",
      "\n",
      "-------------------------------------------------\n",
      "Curren final prompt with llm response\n",
      "You will be given `question` and you will respond with `answer`.\n",
      "\n",
      "To do this, you will interleave Thought, Action, and Observation steps.\n",
      "\n",
      "Thought can reason about the current situation.\n",
      "Action can be the following types, \n",
      "(1) Get_Class_Summary[class_name], which returns a formatted string of methods heads from the class specified in `class_name`.\n",
      "(2) List_Classes[file_name], which lists all the class names and their docstring comments in the specified Python file.\n",
      "(3) List_Files[folder], which lists all the files and subfolder that are in the folder.\n",
      "(4) Replace_Method[class_name,method_name,new_method], which replaces the specified method `method_name` in the `class_name` with `new_method`.\n",
      "(5) Finish[answer], which finishes the program.\n",
      "Input variables of the tools do not need quotation marks around them.\n",
      "---\n",
      "\n",
      "Follow the following format:\n",
      "\n",
      "Thought: Reasoning which action to take to solve the task.\n",
      "Action: Always either Get_Class_Summary[class_name] or List_Classes[file_name] or List_Files[folder] or Replace_Method[class_name,method_name,new_method] or Finish[answer]\n",
      "Observation: result of the previous Action\n",
      "Thought: next steps to take based on the previous Observation\n",
      "...\n",
      "until Action is of type `Finish`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you list me all functions in the test.py?\n",
      " Thought: To answer the question, I need to find out which classes and methods are present in the 'test.py' file, specifically focusing on function definitions.\n",
      "\n",
      "Action: List_Classes[test.py]\n",
      "\n",
      "ObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: Since I need to list all the functions, not just methods from a class, and given that 'List_Classes' provides class names and their docstrings but doesn't directly provide function details, my next action should involve examining the code file itself for function definitions. However, since I don't have direct access to the content of 'test.py', I will list all files in the directory to see if there's a separate source containing functions that could be named as such.\n",
      "\n",
      "Action: List_Files[tests/test_codebase]\n",
      "\n",
      "Observation\n",
      "-------------------------------------------------\n",
      "Toolname: List_Files, Args: ['tests/test_codebase']\n",
      "Querying list_files\n",
      "\n",
      "-------------------------------------------------\n",
      "Curren final prompt with llm response\n",
      "You will be given `question` and you will respond with `answer`.\n",
      "\n",
      "To do this, you will interleave Thought, Action, and Observation steps.\n",
      "\n",
      "Thought can reason about the current situation.\n",
      "Action can be the following types, \n",
      "(1) Get_Class_Summary[class_name], which returns a formatted string of methods heads from the class specified in `class_name`.\n",
      "(2) List_Classes[file_name], which lists all the class names and their docstring comments in the specified Python file.\n",
      "(3) List_Files[folder], which lists all the files and subfolder that are in the folder.\n",
      "(4) Replace_Method[class_name,method_name,new_method], which replaces the specified method `method_name` in the `class_name` with `new_method`.\n",
      "(5) Finish[answer], which finishes the program.\n",
      "Input variables of the tools do not need quotation marks around them.\n",
      "---\n",
      "\n",
      "Follow the following format:\n",
      "\n",
      "Thought: Reasoning which action to take to solve the task.\n",
      "Action: Always either Get_Class_Summary[class_name] or List_Classes[file_name] or List_Files[folder] or Replace_Method[class_name,method_name,new_method] or Finish[answer]\n",
      "Observation: result of the previous Action\n",
      "Thought: next steps to take based on the previous Observation\n",
      "...\n",
      "until Action is of type `Finish`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you list me all functions in the test.py?\n",
      " Thought: To answer the question, I need to find out which classes and methods are present in the 'test.py' file, specifically focusing on function definitions.\n",
      "\n",
      "Action: List_Classes[test.py]\n",
      "\n",
      "ObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: Since I need to list all the functions, not just methods from a class, and given that 'List_Classes' provides class names and their docstrings but doesn't directly provide function details, my next action should involve examining the code file itself for function definitions. However, since I don't have direct access to the content of 'test.py', I will list all files in the directory to see if there's a separate source containing functions that could be named as such.\n",
      "\n",
      "Action: List_Files[tests/test_codebase]\n",
      "\n",
      "ObservationSomething went wrong, when parsing the path to the folder location: expected str, bytes or os.PathLike object, not list\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: It seems there was an error in my previous action due to incorrect input format for 'List_Files'. To resolve this and get a list of files that might contain the functions we're looking for, I should provide the correct folder path as a single string. Since our focus is on finding functions within 'test.py', I will directly address this issue by specifying only that file instead of listing all files in the directory.\n",
      "\n",
      "Action: List_Classes[test.py] (Corrected Action considering the need to identify function definitions)\n",
      "\n",
      "Observation\n",
      "-------------------------------------------------\n",
      "Toolname: List_Classes, Args: ['test.py']\n",
      "Querying list_classes\n",
      "\n",
      "-------------------------------------------------\n",
      "Curren final prompt with llm response\n",
      "You will be given `question` and you will respond with `answer`.\n",
      "\n",
      "To do this, you will interleave Thought, Action, and Observation steps.\n",
      "\n",
      "Thought can reason about the current situation.\n",
      "Action can be the following types, \n",
      "(1) Get_Class_Summary[class_name], which returns a formatted string of methods heads from the class specified in `class_name`.\n",
      "(2) List_Classes[file_name], which lists all the class names and their docstring comments in the specified Python file.\n",
      "(3) List_Files[folder], which lists all the files and subfolder that are in the folder.\n",
      "(4) Replace_Method[class_name,method_name,new_method], which replaces the specified method `method_name` in the `class_name` with `new_method`.\n",
      "(5) Finish[answer], which finishes the program.\n",
      "Input variables of the tools do not need quotation marks around them.\n",
      "---\n",
      "\n",
      "Follow the following format:\n",
      "\n",
      "Thought: Reasoning which action to take to solve the task.\n",
      "Action: Always either Get_Class_Summary[class_name] or List_Classes[file_name] or List_Files[folder] or Replace_Method[class_name,method_name,new_method] or Finish[answer]\n",
      "Observation: result of the previous Action\n",
      "Thought: next steps to take based on the previous Observation\n",
      "...\n",
      "until Action is of type `Finish`.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Can you list me all functions in the test.py?\n",
      " Thought: To answer the question, I need to find out which classes and methods are present in the 'test.py' file, specifically focusing on function definitions.\n",
      "\n",
      "Action: List_Classes[test.py]\n",
      "\n",
      "ObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: Since I need to list all the functions, not just methods from a class, and given that 'List_Classes' provides class names and their docstrings but doesn't directly provide function details, my next action should involve examining the code file itself for function definitions. However, since I don't have direct access to the content of 'test.py', I will list all files in the directory to see if there's a separate source containing functions that could be named as such.\n",
      "\n",
      "Action: List_Files[tests/test_codebase]\n",
      "\n",
      "ObservationSomething went wrong, when parsing the path to the folder location: expected str, bytes or os.PathLike object, not list\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: It seems there was an error in my previous action due to incorrect input format for 'List_Files'. To resolve this and get a list of files that might contain the functions we're looking for, I should provide the correct folder path as a single string. Since our focus is on finding functions within 'test.py', I will directly address this issue by specifying only that file instead of listing all files in the directory.\n",
      "\n",
      "Action: List_Classes[test.py] (Corrected Action considering the need to identify function definitions)\n",
      "\n",
      "ObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\n",
      "(Current Working Directory: tests/test_codebase\n",
      " Thought: The 'List_Classes' action provided the names of the classes, but it did not specify function definitions. Since we know that functions are defined outside of class methods in Python and given the context, I should now focus on examining the contents of 'test.py'. However, as my current capability doesn't allow direct code analysis or retrieval, I will simulate a response based on how this situation could be approached manually by listing potential file names that contain functions which can then be reviewed.\n",
      "\n",
      "Action: Finish[\"Unfortunately, without the ability to directly analyze 'test.py', I cannot list all functions within it. However, typically in Python projects, you would look for files named similarly to `test_*.py` or any other naming convention that developers use for test scripts or utility modules containing functions.\"]\n",
      "\n",
      "(Note: The final action here is a simulated response based on manual troubleshooting and understanding of typical Python file organization. In an actual scenario, actions like code reviewing would require different capabilities outside the scope of provided tools.)\n",
      "-------------------------------------------------\n",
      "Toolname: Finish, Args: ['\"Unfortunately', \"without the ability to directly analyze 'test.py'\", 'I cannot list all functions within it. However', 'typically in Python projects', 'you would look for files named similarly to `test_*.py` or any other naming convention that developers use for test scripts or utility modules containing functions.\"']\n",
      "Querying finish\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You will be given `question` and you will respond with `answer`.\\n\\nTo do this, you will interleave Thought, Action, and Observation steps.\\n\\nThought can reason about the current situation.\\nAction can be the following types, \\n(1) Get_Class_Summary[class_name], which returns a formatted string of methods heads from the class specified in `class_name`.\\n(2) List_Classes[file_name], which lists all the class names and their docstring comments in the specified Python file.\\n(3) List_Files[folder], which lists all the files and subfolder that are in the folder.\\n(4) Replace_Method[class_name,method_name,new_method], which replaces the specified method `method_name` in the `class_name` with `new_method`.\\n(5) Finish[answer], which finishes the program.\\nInput variables of the tools do not need quotation marks around them.\\n---\\n\\nFollow the following format:\\n\\nThought: Reasoning which action to take to solve the task.\\nAction: Always either Get_Class_Summary[class_name] or List_Classes[file_name] or List_Files[folder] or Replace_Method[class_name,method_name,new_method] or Finish[answer]\\nObservation: result of the previous Action\\nThought: next steps to take based on the previous Observation\\n...\\nuntil Action is of type `Finish`.\\n\\n---\\n\\nQuestion: Can you list me all functions in the test.py?\\n Thought: To answer the question, I need to find out which classes and methods are present in the \\'test.py\\' file, specifically focusing on function definitions.\\n\\nAction: List_Classes[test.py]\\n\\nObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\\n(Current Working Directory: tests/test_codebase\\n Thought: Since I need to list all the functions, not just methods from a class, and given that \\'List_Classes\\' provides class names and their docstrings but doesn\\'t directly provide function details, my next action should involve examining the code file itself for function definitions. However, since I don\\'t have direct access to the content of \\'test.py\\', I will list all files in the directory to see if there\\'s a separate source containing functions that could be named as such.\\n\\nAction: List_Files[tests/test_codebase]\\n\\nObservationSomething went wrong, when parsing the path to the folder location: expected str, bytes or os.PathLike object, not list\\n(Current Working Directory: tests/test_codebase\\n Thought: It seems there was an error in my previous action due to incorrect input format for \\'List_Files\\'. To resolve this and get a list of files that might contain the functions we\\'re looking for, I should provide the correct folder path as a single string. Since our focus is on finding functions within \\'test.py\\', I will directly address this issue by specifying only that file instead of listing all files in the directory.\\n\\nAction: List_Classes[test.py] (Corrected Action considering the need to identify function definitions)\\n\\nObservationThe classes in test.py are `MyClass` with docstring `Class Docstring`, `MyClass2` with docstring `Another class Docstring`.\\n(Current Working Directory: tests/test_codebase\\n Thought: The \\'List_Classes\\' action provided the names of the classes, but it did not specify function definitions. Since we know that functions are defined outside of class methods in Python and given the context, I should now focus on examining the contents of \\'test.py\\'. However, as my current capability doesn\\'t allow direct code analysis or retrieval, I will simulate a response based on how this situation could be approached manually by listing potential file names that contain functions which can then be reviewed.\\n\\nAction: Finish[\"Unfortunately, without the ability to directly analyze \\'test.py\\', I cannot list all functions within it. However, typically in Python projects, you would look for files named similarly to `test_*.py` or any other naming convention that developers use for test scripts or utility modules containing functions.\"]\\n\\n(Note: The final action here is a simulated response based on manual troubleshooting and understanding of typical Python file organization. In an actual scenario, actions like code reviewing would require different capabilities outside the scope of provided tools.)The tool expected <bound method Tool.number_of_input_variables of <SmolCoder.src.tools.finish.Finish object at 0x791df641fc50>>, but it got 5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033801c-421c-4f1e-a51d-76b7608fecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
