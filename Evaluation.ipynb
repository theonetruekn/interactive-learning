{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfabc69-87f8-49ea-ab8f-076d0429a33a",
   "metadata": {},
   "source": [
    "# 0. Outline\n",
    "\n",
    "This Jupyter notebooks consists of the following parts:\n",
    "1. Short exploration of the SWE-Benchmark dataset\n",
    "2. SmolCoder, our own implementation of an agent in order to try to solve SWE-Benchmark\n",
    "3. Agentless, our own implementation of the agentless paper, with some enhancements.\n",
    "4. Interactive-Learning, where we combine human feedback with an LLM agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0816198-91cd-478a-9863-9cdc33540ef5",
   "metadata": {},
   "source": [
    "## 0.1 General Imports\n",
    "\n",
    "Please execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a24129-0d25-4b94-9ee3-3874d2b1df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468f9fa-5a75-4bc9-9d28-1e886a0bf961",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. The SWE-Benchmark dataset\n",
    "\n",
    "We have two datasets we can use for predicting `swe-bench.json` which has 2200 entries and `swe-bench-lite.json` which has 224 entries, they are from the [SWE-Bench](https://github.com/princeton-nlp/SWE-bench/tree/main).\n",
    "We have another new one `test-00000-of-00001.parquet` which is the swe-bench-verifed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "715d876a-03a8-4eaf-9c01-1bd2317d1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2294 entries, 0 to 2293\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   base_commit               2294 non-null   object             \n",
      " 1   hints_text                2294 non-null   object             \n",
      " 2   created_at                2294 non-null   datetime64[ns, UTC]\n",
      " 3   test_patch                2294 non-null   object             \n",
      " 4   repo                      2294 non-null   object             \n",
      " 5   problem_statement         2294 non-null   object             \n",
      " 6   version                   2294 non-null   float64            \n",
      " 7   instance_id               2294 non-null   object             \n",
      " 8   FAIL_TO_PASS              2294 non-null   object             \n",
      " 9   PASS_TO_PASS              2294 non-null   object             \n",
      " 10  environment_setup_commit  2294 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(9)\n",
      "memory usage: 197.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# For the lite benchmark\n",
    "# df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "\n",
    "# For the swe-verified\n",
    "# df = pd.read_parquet(\"Evaluation/test-00000-of-00001.parquet\")\n",
    "\n",
    "# For the full swe\n",
    "df = pd.read_json(\"Evaluation/swe-bench.json\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b0387-5aa9-43be-9076-6e31eb5f58ed",
   "metadata": {},
   "source": [
    "After we used our LLM on the dataset to generate solutions to the problems, our output needs to be in the following format:\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"<Unique task instance ID>\",\n",
    "    \"model_patch\": \"<.patch file content string>\",\n",
    "    \"model_name_or_path\": \"<Model name here (i.e. SWE-Llama-13b)>\",\n",
    "}\n",
    "```\n",
    "With multiple prediction like this `[<prediction 1>, <prediction 2>,... <prediction n>]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cd217-25f3-4879-9a7c-b9fa7df0eb6e",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "{\n",
    "    \"instance_id\": \"django__django-15127\",\n",
    "    \"model_name_or_path\": \"test\",\n",
    "    \"model_patch\": \"--- a/django/contrib/messages/storage/base.py\\n+++ b/django/contrib/messages/storage/base.py\\n@@ -52,6 +52,7 @@\\n                 if self._loaded_data is None:\\n                     self._loaded_data = self.load()\\n                 level, message, extra_tags = self._loaded_data\\n+                extra_tags.update(self.get_level_tags())\\n                 return {\\n                     'message': message,\\n                     'level': level,\\n\"\n",
    "  },\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0e801-44ba-45ea-9548-d22c6b682fd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. SmolCoder\n",
    "\n",
    "SmolCoder is our own try to program an agent that solves the SWE-Benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a82b1-185c-4b45-aad8-ed0efb059b5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1 Testing SmolCoder works\n",
    "\n",
    "This requires starting the `phi3:latest` model, with ollama.\n",
    "This is for the Master Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a127113-b474-4e59-93f9-bb9c8f1ba82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lupos/Agentless', '/home/lupos/miniconda3/envs/llm/lib/python311.zip', '/home/lupos/miniconda3/envs/llm/lib/python3.11', '/home/lupos/miniconda3/envs/llm/lib/python3.11/lib-dynload', '', '/home/lupos/miniconda3/envs/llm/lib/python3.11/site-packages', '/home/lupos/interactive-learning/SmolCoder']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(str(os.path.abspath('SmolCoder')))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14072627-c353-4ee3-aaab-41fb32758e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "from SmolCoder.src.agent_wrapper import AgentWrapper\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.replace_method import ReplaceMethod\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.tools.execute_python import ExecutePythonCode\n",
    "from SmolCoder.src.tools.show_method import ShowMethodBody\n",
    "from SmolCoder.src.tools.move_folder import MoveFolder\n",
    "from SmolCoder.src.tools.human_interaction import HumanInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237bac3c-59a8-4d40-ab75-0cc06c999082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Definition\n",
    "class_sumary = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "replace_method = ReplaceMethod()\n",
    "finish = Finish()\n",
    "execute_python = ExecutePythonCode()\n",
    "show_method = ShowMethodBody()\n",
    "move_folder = MoveFolder()\n",
    "human_interaction = HumanInteraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8b706-bc7f-486b-8f55-63d47f19e693",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.2 Testing Execute Python Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b0734-bc24-40ff-9c95-6fd82f88d021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tools = Toolkit([execute_python])\n",
    "\n",
    "agent = AgentWrapper(agent_name=\"SmolCoder\",\n",
    "                     toolkit=tools,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "prompt = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0103363a-f353-4b72-9d19-ee9959167721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = agent.predict(prompt)\n",
    "#print(\"RESULT: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94d05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(smolCoder.inspect_history(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78b30-5c0e-49c3-b605-366f1eb6f287",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3 SmolCoder on SWE\n",
    "\n",
    "This tests SmolCoder on a single Instance of the SWE-Benchmark.\n",
    "This is without first trying to reproduce the bug, just barebones ReAct with tools.\n",
    "This is for the master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74e473e-0e6b-4b57-a3b1-ed9c97686331",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd3f9919-5077-45cd-8768-a8d96b6aa8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mpredict(df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc19c91e-3fc0-471a-a479-c5bff68803fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m toolkit \u001b[38;5;241m=\u001b[39m Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n\u001b[0;32m----> 4\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgentWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43magent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolCoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtoolkit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoolkit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphi3:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mworking_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: AgentWrapper.__init__() missing 1 required positional argument: 'dummy_model'"
     ]
    }
   ],
   "source": [
    "# print(smol_coder.in# toolkit = Toolkit([human_interaction, finish])\n",
    "toolkit = Toolkit([human_interaction, list_classes, list_files, replace_method, show_method, move_folder, finish])\n",
    "\n",
    "agent = AgentWrapper(\n",
    "                     agent_name=\"SmolCoder\",\n",
    "                     toolkit=toolkit,\n",
    "                     mode=0,\n",
    "                     model=\"phi3:latest\",\n",
    "                     working_directory=\"repos\",\n",
    "                     logging_enabled=True\n",
    "                    )\n",
    "\n",
    "print(agent.name)\n",
    "print(\"----------------\")\n",
    "print(agent.predict(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6494f-e13c-4e01-a860-86a8af311e54",
   "metadata": {},
   "source": [
    "## Generating all Predictions\n",
    "\n",
    "When running this on a server, it could happen that something crashed or an error is thrown which doesn't get catches, as such it is important to write the changes to disk for each entry in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55df9f9d-f75e-4417-9f5d-83e104ff0107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentStub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#tools = Toolkit([class_sumary, list_classes, list_files, finish])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#model = LLM(\"phi3:latest\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m stub \u001b[38;5;241m=\u001b[39m \u001b[43mAgentStub\u001b[49m()\n\u001b[1;32m     13\u001b[0m agent \u001b[38;5;241m=\u001b[39m AgentWrapper(stub, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m checkpoint_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AgentStub' is not defined"
     ]
    }
   ],
   "source": [
    "# This implementation uses checkpoints, this means if the program \n",
    "# is interuppted it can start again, where it left oft.\n",
    "\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "#tools = Toolkit([class_sumary, list_classes, list_files, finish])\n",
    "#model = LLM(\"phi3:latest\")\n",
    "#smol_coder = SmolCoder(model, Path(\"repos\"), tools)\n",
    "#agent = AgentWrapper(smol_coder, working_directory=\"repos\", name=\"SmolCoder\")\n",
    "\n",
    "stub = AgentStub()\n",
    "agent = AgentWrapper(stub, \"repos\")\n",
    "\n",
    "checkpoint_file = 'checkpoint.txt'\n",
    "resume_index = 0\n",
    "\n",
    "activated = 1\n",
    "\n",
    "if activated:\n",
    "    # Check if checkpoint file exists and read the last processed index\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            resume_index = int(f.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading checkpoint file: {e}\")\n",
    "    \n",
    "    if resume_index < len(df) - 1:\n",
    "        # Open a file to save predictions\n",
    "        with open('predictions.json', 'a', encoding=\"utf-8-sig\") as json_file:\n",
    "            if resume_index == 0:\n",
    "                json_file.write('[')  # Start of JSON array\n",
    "                json_file.write('\\n')\n",
    "            # Generating our solution\n",
    "            for index, row in df.iterrows():\n",
    "                if index % 10 == 0: print(\"Current idx: \" + str(index))\n",
    "                # Skip rows that were already processed\n",
    "                if index < resume_index:\n",
    "                    continue\n",
    "        \n",
    "                predictions = {\n",
    "                    \"instance_id\": row[\"instance_id\"],\n",
    "                    \"model_patch\": agent.predict(row),\n",
    "                    \"model_name_or_path\": agent.name\n",
    "                }\n",
    "                # Convert the dictionary to a JSON formatted string and write to file\n",
    "                json_data = json.dumps(predictions, indent=4)\n",
    "                json_file.write(json_data)\n",
    "                if index < len(df) - 1:\n",
    "                    json_file.write(',')\n",
    "                json_file.write('\\n')\n",
    "        \n",
    "                with open(checkpoint_file, 'w') as f:\n",
    "                    f.write(str(index))\n",
    "                    \n",
    "            if index == len(df) - 1:\n",
    "                json_file.write(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844ff1e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Self-implemented Agentless \n",
    "\n",
    "This is for testing the agentless-branch.  \n",
    "Based on [agentless paper](https://arxiv.org/abs/2407.01489).  \n",
    "**This section only works on the agentless branch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cbbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 225 entries, 0 to 224\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   repo                      225 non-null    object             \n",
      " 1   instance_id               225 non-null    object             \n",
      " 2   base_commit               225 non-null    object             \n",
      " 3   patch                     225 non-null    object             \n",
      " 4   test_patch                225 non-null    object             \n",
      " 5   problem_statement         225 non-null    object             \n",
      " 6   hints_text                225 non-null    object             \n",
      " 7   created_at                225 non-null    datetime64[ns, UTC]\n",
      " 8   version                   225 non-null    float64            \n",
      " 9   FAIL_TO_PASS              225 non-null    object             \n",
      " 10  PASS_TO_PASS              225 non-null    object             \n",
      " 11  environment_setup_commit  225 non-null    object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), object(10)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from SmolCoder.src.llm_wrapper import LLM\n",
    "from SmolCoder.src.prompting_strategy import PromptingStrategy\n",
    "from SmolCoder.src.toolkit import Toolkit\n",
    "from SmolCoder.src.tools.list_methods import ListMethods\n",
    "from SmolCoder.src.tools.list_files import ListFiles\n",
    "from SmolCoder.src.tools.list_classes import ListClasses\n",
    "from SmolCoder.src.tools.finish import Finish\n",
    "from SmolCoder.src.meta_tokenizer import MetaTokenizer\n",
    "\n",
    "from SmolCoder.src.agent import SmolCoder\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import os\n",
    "import validators\n",
    "import shutil\n",
    "\n",
    "df = pd.read_json(\"Evaluation/swe-bench-lite.json\")\n",
    "df.info()\n",
    "\n",
    "list_methods = ListMethods()\n",
    "list_classes = ListClasses()\n",
    "list_files = ListFiles()\n",
    "finish = Finish()\n",
    "\n",
    "toolkit = Toolkit([list_methods, list_classes, list_files, finish])\n",
    "\n",
    "smol = SmolCoder(phase=3, model=LLM(\"llama3.1\", openai=[False, \"None\"], logger=None), codebase_dir= Path(\"test_codebase/\"), logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "smol(df.iloc[0][\"problem_statement\"], start_cwd=\"./repos/sqlfluff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573fac2-7e3f-4ad9-957f-cd5b86871d5a",
   "metadata": {},
   "source": [
    "# 4. Interactive-Learning\n",
    "\n",
    "This is for testing a agent version with it's main focus being interactive-learning i.e. interaction with humans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670df9e2-8886-410e-b281-0a63f57bd98c",
   "metadata": {},
   "source": [
    "## 4.1 Test-Cases \n",
    "\n",
    "The following are specific tasks instances from the SWE-Bench dataset, that [SWE-Agent](https://arxiv.org/abs/2405.15793) managed to solve and appear in the appendix of their paper(page 45)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23915133-b6f7-40f9-a5e8-ec8599e7f048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_commit</th>\n",
       "      <th>hints_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>test_patch</th>\n",
       "      <th>repo</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>version</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>FAIL_TO_PASS</th>\n",
       "      <th>PASS_TO_PASS</th>\n",
       "      <th>environment_setup_commit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>091991be0da19de9108dbe5e3752917fea3d7fdc</td>\n",
       "      <td>Ugh. This should have been caught and replaced...</td>\n",
       "      <td>2014-11-01 02:20:16+00:00</td>\n",
       "      <td>diff --git a/test_requests.py b/test_requests....</td>\n",
       "      <td>psf/requests</td>\n",
       "      <td>method = builtin_str(method) problem\\nIn reque...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>psf__requests-2317</td>\n",
       "      <td>[test_requests.py::RequestsTestCase::test_HTTP...</td>\n",
       "      <td>[test_requests.py::RequestsTestCase::test_BASI...</td>\n",
       "      <td>091991be0da19de9108dbe5e3752917fea3d7fdc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   base_commit  \\\n",
       "1184  091991be0da19de9108dbe5e3752917fea3d7fdc   \n",
       "\n",
       "                                             hints_text  \\\n",
       "1184  Ugh. This should have been caught and replaced...   \n",
       "\n",
       "                    created_at  \\\n",
       "1184 2014-11-01 02:20:16+00:00   \n",
       "\n",
       "                                             test_patch          repo  \\\n",
       "1184  diff --git a/test_requests.py b/test_requests....  psf/requests   \n",
       "\n",
       "                                      problem_statement  version  \\\n",
       "1184  method = builtin_str(method) problem\\nIn reque...      2.4   \n",
       "\n",
       "             instance_id                                       FAIL_TO_PASS  \\\n",
       "1184  psf__requests-2317  [test_requests.py::RequestsTestCase::test_HTTP...   \n",
       "\n",
       "                                           PASS_TO_PASS  \\\n",
       "1184  [test_requests.py::RequestsTestCase::test_BASI...   \n",
       "\n",
       "                      environment_setup_commit  \n",
       "1184  091991be0da19de9108dbe5e3752917fea3d7fdc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"instance_id\"] == \"psf__requests-2317\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4682408-1bf3-404d-b1e2-b9de2bcf9058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_commit</th>\n",
       "      <th>hints_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>test_patch</th>\n",
       "      <th>repo</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>version</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>FAIL_TO_PASS</th>\n",
       "      <th>PASS_TO_PASS</th>\n",
       "      <th>environment_setup_commit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>182cc539b8154c0710fcea7e522267e42eba8899</td>\n",
       "      <td>Did a little investigation, this is we're actu...</td>\n",
       "      <td>2022-03-04 00:01:54+00:00</td>\n",
       "      <td>diff --git a/tests/checkers/unittest_misc.py b...</td>\n",
       "      <td>pylint-dev/pylint</td>\n",
       "      <td>\"--notes\" option ignores note tags that are en...</td>\n",
       "      <td>2.13</td>\n",
       "      <td>pylint-dev__pylint-5859</td>\n",
       "      <td>[tests/checkers/unittest_misc.py::TestFixme::t...</td>\n",
       "      <td>[tests/checkers/unittest_misc.py::TestFixme::t...</td>\n",
       "      <td>3b2fbaec045697d53bdd4435e59dbfc2b286df4b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   base_commit  \\\n",
       "1341  182cc539b8154c0710fcea7e522267e42eba8899   \n",
       "\n",
       "                                             hints_text  \\\n",
       "1341  Did a little investigation, this is we're actu...   \n",
       "\n",
       "                    created_at  \\\n",
       "1341 2022-03-04 00:01:54+00:00   \n",
       "\n",
       "                                             test_patch               repo  \\\n",
       "1341  diff --git a/tests/checkers/unittest_misc.py b...  pylint-dev/pylint   \n",
       "\n",
       "                                      problem_statement  version  \\\n",
       "1341  \"--notes\" option ignores note tags that are en...     2.13   \n",
       "\n",
       "                  instance_id  \\\n",
       "1341  pylint-dev__pylint-5859   \n",
       "\n",
       "                                           FAIL_TO_PASS  \\\n",
       "1341  [tests/checkers/unittest_misc.py::TestFixme::t...   \n",
       "\n",
       "                                           PASS_TO_PASS  \\\n",
       "1341  [tests/checkers/unittest_misc.py::TestFixme::t...   \n",
       "\n",
       "                      environment_setup_commit  \n",
       "1341  3b2fbaec045697d53bdd4435e59dbfc2b286df4b  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"instance_id\"] == \"pylint-dev__pylint-5859\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba06ea-b3be-4ff7-aa43-e40525cdf79d",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating the Instances with Interactive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5cf8dc8-3f6b-43d6-8dc4-801e30607ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SmolCoder.src.llm_wrapper import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87662a3a-d16c-4044-8266-ee8102fded33",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\"llama3.1\", openai=[False, \"None\"], logger=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870089dd-4451-46ba-a06f-75f68a89e3aa",
   "metadata": {},
   "source": [
    "### 4.2.1 First test Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7fc3654-5f52-488d-aff2-ccf372b43802",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_description = df[df[\"instance_id\"] == \"psf__requests-2317\"][\"problem_statement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2d32316-e6fa-4511-a165-0deba9bffd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_code = (\n",
    "    \"import os\\n\"\n",
    "    \"from collections import Mapping\\n\"\n",
    "    \"from datetime import datetime\\n\\n\"\n",
    "    \"from .auth import _basic_auth_str\\n\"\n",
    "    \"from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str\\n\"\n",
    "    \"from .cookies import (\\n\"\n",
    "    \"    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\\n\"\n",
    "    \"from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\\n\"\n",
    "    \"from .hooks import default_hooks, dispatch_hook\\n\"\n",
    "    \"from .utils import to_key_val_list, default_headers, to_native_string\\n\"\n",
    "    \"from .exceptions import (\\n\"\n",
    "    \"    TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)\\n\"\n",
    "    \"from .structures import CaseInsensitiveDict\\n\"\n",
    "    \"from .adapters import HTTPAdapter\\n\"\n",
    "    \"from .utils import (\\n\"\n",
    "    \"    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\\n\"\n",
    "    \"    get_auth_from_url\\n\"\n",
    "    \")\\n\"\n",
    "    \"from .status_codes import codes\\n\"\n",
    "    \"# formerly defined here, reexposed here for backward compatibility\\n\"\n",
    "    \"from .models import REDIRECT_STATI\\n\"\n",
    "    \"\\n\\n\"\n",
    "    \"def request(self, method, url,\"\n",
    "    \"        params=None,\"\n",
    "    \"        data=None,\"\n",
    "    \"        headers=None,\"\n",
    "    \"        cookies=None,\"\n",
    "    \"        files=None,\"\n",
    "    \"        auth=None,\"\n",
    "    \"        timeout=None,\"\n",
    "    \"        allow_redirects=True,\"\n",
    "    \"        proxies=None,\"\n",
    "    \"        hooks=None,\"\n",
    "    \"        stream=None,\"\n",
    "    \"        verify=None,\"\n",
    "    \"        cert=None,\"\n",
    "    \"        json=None):\"\n",
    "    '        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\\n'\n",
    "    '        Returns :class:`Response <Response>` object.\\n'\n",
    "    \"        :param method: method for the new :class:`Request` object.\\n\"\n",
    "    \"        :param url: URL for the new :class:`Request` object.\\n\"\n",
    "    \"        :param params: (optional) Dictionary or bytes to be sent in the query\\n\"\n",
    "    \"            string for the :class:`Request`.\\n\"\n",
    "    \"        :param data: (optional) Dictionary or bytes to send in the body of the\\n\"\n",
    "    \"            :class:`Request`.\\n\"\n",
    "    \"        :param json: (optional) json to send in the body of the\\n\"\n",
    "    \"            :class:`Request`.\\n\"\n",
    "    \"        :param headers: (optional) Dictionary of HTTP Headers to send with the\\n\"\n",
    "    \"            :class:`Request`.\\n\"\n",
    "    \"        :param cookies: (optional) Dict or CookieJar object to send with the\\n\"\n",
    "    \"            :class:`Request`.\\n\"\n",
    "    \"        :param files: (optional) Dictionary of `'filename': file-like-objects`\\n\"\n",
    "    \"            for multipart encoding upload.\\n\"\n",
    "    \"        :param auth: (optional) Auth tuple or callable to enable\\n\"\n",
    "    \"            Basic/Digest/Custom HTTP Auth.\\n\"\n",
    "    \"        :param timeout: (optional) How long to wait for the server to send\\n\"\n",
    "    \"            data before giving up, as a float, or a (`connect timeout, read\\n\"\n",
    "    \"            timeout <user/advanced.html#timeouts>`_) tuple.\\n\"\n",
    "    \"        :type timeout: float or tuple\\n\"\n",
    "    \"        :param allow_redirects: (optional) Set to True by default.\\n\"\n",
    "    \"        :type allow_redirects: bool\\n\"\n",
    "    \"        :param proxies: (optional) Dictionary mapping protocol to the URL of\\n\"\n",
    "    \"            the proxy.\\n\"\n",
    "    \"        :param stream: (optional) whether to immediately download the response\\n\"\n",
    "    \"            content. Defaults to `False`.\\n\"\n",
    "    \"        :param verify: (optional) if `True`, the SSL cert will be verified.\\n\"\n",
    "    \"            A CA_BUNDLE path can also be provided.\\n\"\n",
    "    \"        :param cert: (optional) if String, path to ssl client cert file (.pem).\\n\"\n",
    "    \"            If Tuple, ('cert', 'key') pair.\\n\"\n",
    "    '        \"\"\"\\n\\n'\n",
    "    \"        method = builtin_str(method)\\n\\n\"\n",
    "    \"        # Create the Request.\\n\"\n",
    "    \"        req = Request(\\n\"\n",
    "    \"            method = method.upper(),\\n\"\n",
    "    \"            url = url,\\n\"\n",
    "    \"            headers = headers,\\n\"\n",
    "    \"            files = files,\\n\"\n",
    "    \"            data = data or {},\\n\"\n",
    "    \"            json = json,\\n\"\n",
    "    \"            params = params or {},\\n\"\n",
    "    \"            auth = auth,\\n\"\n",
    "    \"            cookies = cookies,\\n\"\n",
    "    \"            hooks = hooks,\\n\"\n",
    "    \"        )\\n\"\n",
    "    \"        prep = self.prepare_request(req)\\n\"\n",
    "    \"        proxies = proxies or {}\\n\"\n",
    "    \"        settings = self.merge_environment_settings(\\n\"\n",
    "    \"            prep.url, proxies, stream, verify, cert\\n\"\n",
    "    \"        )\\n\"\n",
    "    \"        # Send the request.\\n\"\n",
    "    \"        send_kwargs = {\\n\"\n",
    "    \"            'timeout': timeout,\\n\"\n",
    "    \"            'allow_redirects': allow_redirects,\\n\"\n",
    "    \"        }\\n\"\n",
    "    \"        send_kwargs.update(settings)\\n\"\n",
    "    \"        resp = self.send(prep, **send_kwargs)\\n\\n\"\n",
    "    \"        return resp\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45cd233d-b81d-40ab-ba5a-fe6ee202d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"You are a software engineer coding agent.\"\n",
    "    \"You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is,\"\n",
    "    \"to solve this issue. A human will help you with that task, by providing help.\\n\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"For that you will now be given the description of the GitHub Issue:\\n\"\n",
    "    f\"{github_description}\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"The human, will now give you the code they think is relevant to the Issue:\\n\"\n",
    "    f\"{relevant_code}\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"Your task is now given the description of the issue and the provide relevant code, to fix the Issue.\\n\"\n",
    "    \"End your response when your are finished with the following: --STOP-- \\n\"\n",
    "    \"For that try to think step for step and in the end output the corrected code:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cb1e8f3-6865-4c4a-9ba6-1a733407e461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Step 1 is understanding what the problem is\n",
      "2. Step 2 is Identifying why this problem occurs\n",
      "3. Step 3 is identifying where this problem comes from (in terms of lines of code)\n",
      "4. Step 4 is proposing a correction for the issue \n",
      "5. Step 5 is correcting the problematic code.\n",
      "So let's start:\n",
      "Step 1: Understanding what the problem is.\n",
      "We can see that there are many parameters available in the `request` function of this class but then it says \"problem\" at the beginning of the code with line number 1184 and \"method = builtin_str(method) problem\\nIn reque...\" which seems to indicate an issue with method conversion in the request function. Therefore, the problem seems to be related to converting the `method` parameter into a string.\n",
      "Step 2: Identifying why this problem occurs\n",
      "This might be due to the fact that we're passing something that's not a string into the `method` parameter, or maybe it's trying to convert some variable that shouldn't be converted. This could also be related to an issue with the method conversion logic in the code.\n",
      "Step 3: Identifying where this problem comes from\n",
      "The problematic line of code is: \n",
      "```python\n",
      "method = builtin_str(method)\n",
      "```\n",
      "And then we have a comment saying \"problem\" at the beginning of the code which points us towards line number 1184. The issue seems to be directly related to how `method` is being converted into a string using `builtin_str(method)`.\n",
      "\n",
      "Step 4: Proposing a correction for this issue\n",
      "The best solution would be to check if the method parameter is actually a string, and if not then raise an error message so that we know what's going wrong. This can be achieved by adding some conditions in the problematic line of code like this:\n",
      "```python\n",
      "if not isinstance(method, str):\n",
      "    raise ValueError(\"Method must be a string\")\n",
      "method = builtin_str(method)\n",
      "```\n",
      "This way, when you're calling `request` function with something other than a string as method parameter, it will now throw an error saying \"Method must be a string\", which is much better than the silent failure we were getting earlier.\n",
      "\n",
      "Step 5: Correcting the problematic code.\n",
      "Here's how the corrected code would look like:\n",
      "```python\n",
      "def request(self, method, url,        params=None,        data=None,        headers=None,        cookies\n"
     ]
    }
   ],
   "source": [
    "print(llm.query_completion(prompt, \"--STOP--\", seed=46))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a939b3c-c049-49c2-b485-4572cf5d3fb3",
   "metadata": {},
   "source": [
    "**The correct code as found from the pull request should be:**\n",
    "```python\n",
    "method = to_native_string(method)\n",
    "```\n",
    "Explanation:\n",
    "```\n",
    " The agent edited the sessions.py file to check if the method was a\n",
    "bytes object and, if so, decoded it to ASCII before applying the builtin_str function.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9de7f-4d83-4237-9b55-d1b71f8cf6cd",
   "metadata": {},
   "source": [
    "### 4.2.2 Second test Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd05be6f-bfd1-44d0-936a-3529cf46a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_description = df[df[\"instance_id\"] == \"pylint-dev__pylint-5859\"][\"problem_statement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00152d03-e0a6-491c-962b-99f18aee6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_code = (\n",
    "    \"def open(self):\\n\"\n",
    "    \"       super().open()\\n\\n\"\n",
    "    \"       notes = \\\"|\\\".join(re.escape(note) for note in self.config.notes)\\n\"\n",
    "    \"       if self.config.notes_rgx:\\n\"\n",
    "    \"           regex_string = rf\\\"#\\\\s*({notes}|{self.config.notes_rgx})\\\\b\\\"\\n\"\n",
    "    \"       else:\\n\"\n",
    "    \"           regex_string = rf\\\"#\\\\s*({notes})\\\\b\\\"\\n\"\n",
    "    \"       self._fixme_pattern = re.compile(regex_string, re.I)\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "389f1900-2c04-4ccc-b0a0-45641d9085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"You are a software engineer coding agent.\"\n",
    "    \"You will be given a description of a `GitHub issue` and it's corresponding codebase and your task is,\"\n",
    "    \"to solve this issue. A human will help you with that task, by providing help.\\n\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"For that you will now be given the description of the GitHub Issue:\\n\"\n",
    "    f\"{github_description}\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"The human, will now give you the code they think is relevant to the Issue:\\n\"\n",
    "    f\"{relevant_code}\"\n",
    "    \"--------------------------------------------\\n\"\n",
    "    \"Your task is now given the description of the issue and the provide relevant code, to fix the Issue.\\n\"\n",
    "    \"End your response when your are finished with the following: --STOP-- \\n\"\n",
    "    \"For that try to think step for step and in the end output the corrected code:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3af411de-041c-489f-9fab-b9be9f7ffebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Read the problem statement:\n",
      "The issue seems to be related to a bug where the \"--notes\" option ignores note tags that are enclosed within parentheses. This means if a note tag has any characters within its parentheses, they are being ignored.\n",
      "\n",
      "2. Identify how this bug could have occurred:\n",
      "This could happen because of an incorrect implementation or maybe an error in regular expression syntax, as it seems like the `self._fixme_pattern` is trying to match the notes with some regex pattern. This might not be correctly matching notes that have enclosed characters within parentheses.\n",
      "\n",
      "3. Analyze and understand how the given code works:\n",
      "The provided code snippet seems to be part of a class method called `open(self)`. It first calls its parent's `open()` method (using `super().open()`) and then does some setup for notes and regex patterns. The main logic is in creating a regular expression pattern using `self.config.notes_rgx` or just `self.config.notes`, depending on whether `self.config.notes_rgx` is set.\n",
      "\n",
      "4. Identify the correct code to fix this issue:\n",
      "To fix the issue, we should make sure that our regex pattern correctly matches notes with enclosed characters within parentheses. We could try escaping these enclosed characters so they are treated as literal characters by the regex engine.\n",
      "\n",
      "5. Correcting the bug:\n",
      "Let's modify the line where `regex_string` is created to include escaped versions of the enclosed characters. This will ensure our regex matches them correctly, even if they're inside parentheses.\n",
      "```python\n",
      "import re\n",
      "\n",
      "class Config:\n",
      "    def __init__(self):\n",
      "        self.notes = [\"Note 1\", \"Note 2\", \"(Note with enclosed chars)\"]\n",
      "        self.notes_rgx = None\n",
      "\n",
      "def open(self):\n",
      "       super().open()\n",
      "\n",
      "       notes = \"|\".join(re.escape(note) for note in self.config.notes)\n",
      "       if self.config.notes_rgx:\n",
      "           regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n",
      "       else:\n",
      "           # Correcting the bug here\n",
      "           enclosed_chars = r\"\\(.*?\\)|\\(.*?\\)\"\n",
      "           notes_with_enclosed = \"|\".join(f\"{re.escape(note)}{enclosed_chars}\" for note in self.config.notes)\n",
      "           regex_string = rf\"#\\s*({notes}|{notes_with_enclosed})\\b\"\n",
      "       self._fixme_pattern = re.compile(regex_string, re.I)\n",
      "\n",
      "# Test the corrected code\n"
     ]
    }
   ],
   "source": [
    "print(llm.query_completion(prompt, \"--STOP--\", seed=44))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e64ba-8645-4b64-b9b2-129ba30af184",
   "metadata": {},
   "source": [
    "**The correct code as found from the pull request should be:**\n",
    "```python\n",
    " def open(self):\n",
    "    super().open()\n",
    "\n",
    "    notes = \"|\".join(re.escape(note) for note in self.config.notes)\n",
    "    if self.config.notes_rgx:\n",
    "        regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})(?=(:|\\s|\\Z))\"\n",
    "    else:\n",
    "        regex_string = rf\"#\\s*({notes})(?=(:|\\s|\\Z))\"\n",
    "\n",
    "    self._fixme_pattern = re.compile(regex_string, re.I)\n",
    "```\n",
    "Explanation:\n",
    "```\n",
    "The agent located the regular expression responsible for matching note tags within the\n",
    "open method of the EncodingChecker class. It modified the regular expression to\n",
    "handle punctuation-only note tags by replacing the word boundary \\b with a lookahead\n",
    "assertion (?\\W|$).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec9039-155b-49bd-ad88-a156ea4c73fb",
   "metadata": {},
   "source": [
    "Tried it with the seed 42-44, all dont give corretc results, not even near."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19892a77-93eb-4d4d-b78e-25eb842f76d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
